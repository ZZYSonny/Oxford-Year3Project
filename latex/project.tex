\documentclass{article}
\usepackage{minted}
\begin{document}

\section{Common Objects}
\subsection{Shared Variable}
The usage of shared variables is common in concurrent datatypes. For example, some concurrent datatypes may temporarily store an integer value sent by a thread in its variable. However, CSP is more like a functional programming language and does not support mutable variables. 

The behavior of a shared variable can be captured by a recursive function in CSP. The recursive function represents a thread holding the value of variable in the function parameter. At any time, the variable thread is willing to answer a query for the variable value in channel \textbf{getChan}. Or the thread can receive an update on the variable value in channel \textbf{getChan}, after which the function recurses with the new variable value.

\begin{minted}{haskell}
    Var(value) = getValue!value -> Var(value)
          [] setValue?value -> Var(value)  
\end{minted}
In order for other objects to use the shared variable, the variable function needs to run in parallel with threads, and synchronizing on \textbf{getChan} and \textbf{setChan} events. It is convenient to implement this in a function \textbf{runWith}, to run a process in synchronization with the variable process.

\begin{minted}{haskell}
instance VarA = ModuleVariable({0,1,2},0)
P = VarA::getValue?a -> VarA::setValue!a -> STOP
\end{minted}

\subsubsection{Semaphore}


\section{Testing Objects}
\subsection{ABC}
In the ABC object, three threads are involved in each round of synchronization. On the higher level, three different threads call function \textbf{syncA}, \textbf{syncB}, \textbf{syncC} with their parameter respectively, and each function returns the parameters of two other function calls.

The ABC object may be implemented with semaphore. In each round

\begin{minted}{scala}
    class ABC[A,B,C] extends ABCT[A,B,C]{
        // The identities of the current (or previous) threads.
        private var a: A = _
        private var b: B = _
        private var c: C = _
      
        // Semaphores to signal that threads can write their identities.
        private val aClear = MutexSemaphore()
        private val bClear, cClear = SignallingSemaphore()
      
        // Semaphores to signal that threads can collect their results. 
        private val aSignal, bSignal, cSignal = SignallingSemaphore()
      
        def syncA(me: A) = {
          aClear.down         // (A1)
          a = me; bClear.up   // signal to b at (B1)
          aSignal.down        // (A2)
          val result = (b,c)
          bSignal.up          // signal to b at (B2)
          result
        }
      
        def syncB(me: B) = {
          bClear.down         // (B1)
          b = me; cClear.up   // signal to C at (C1)
          bSignal.down        // (B2)
          val result = (a,c)
          cSignal.up          // signal to c at (C2)
          result
        }
      
        def syncC(me: C) = {
          cClear.down         // (C1)
          c = me; aSignal.up  // signal to A at (A2)
          cSignal.down        // (C2)
          val result = (a,b)
          aClear.up           // signal to an A on the next round at (A1)
          result
        }
      }      
\end{minted}

\begin{itemize}
    \item Initially \textbf{aClear} semaphore is up
    \item A thread calling \textbf{aSync} takes down the \textbf{aClear} semaphore, puts down its value, and raises \textbf{bClear} semaphore, and finally waits for the \textbf{aSignal} semaphore to raise.
    \item Another thread calling \textbf{bSync} takes down the \textbf{bClear} semaphore, put down its value, and raises \textbf{cClear} semaphore, and waits for \textbf{bSignal} semaphore to raise.
    \item One more thread calling \textbf{cSync} takes down the \textbf{cClear} semaphore, put down its value, and raises \textbf{aSignal} semaphore, and waits for \textbf{cSignal} semaphore to raise.
    \item The first thread is able to continue. The thread takes a copy of the other two argument, raises the \textbf{bSignal} thread, and exits with the arguments pair.
    \item The second thread is able to continue and does the similar thing as the first thread. Before exiting, the second thread raises \textbf{cSignal}.
    \item The last thread is then able to continue. Before exiting, the last thread raises \textbf{aClear}, allowing a new round to start.
\end{itemize}

Using the shared variable and semaphore module, it is easy to translate the Scala implementation to a CSP implementation. 

Unlike Monitor in Java and Scala, raising a semaphore immediately allows another thread waiting to \textbf{down} the semaphore to continue. So in the semaphore implementation, it is essential to take a copy of the two other argument, before raising the semaphore for the next thread. 

On the other hand, what if the implementation of \textbf{syncA} does not take a copy of the argument? It turns out the ABC object still works correctly when only three threads are involved, but fails the linearization test with four threads.

\subsubsection{Testing}
Using the standard linearization testing technique, the following \textbf{Sync} channel can be used to represent the synchronization of three involved threads. For example, the event \textbf{Sync.t1.a.b.c.t2.d.e.f.t3.g.h.i} represents the synchronizations of three threads, \textbf{t1,t2,t3}, in which the first thread \textbf{t1} calls \textbf{aSync} with \textbf{a} and returns \textbf{(b,c)}, the second thread \textbf{t2} calls \textbf{bSync} with \textbf{d} and returns \textbf{(e,f)}, and last thread \textbf{t3} calls \textbf{cSync} with \textbf{g} and returns \textbf{(h,i)}. The spec process should then check each synchronization point that the return value for each functional call is the pair of arguments of two other function call.

\begin{minted}[breaklines]{haskell}
channel Sync: TypeThreadID.TypeData.TypeData.TypeData. TypeThreadID.TypeData.TypeData.TypeData. TypeThreadID.TypeData.TypeData.TypeData

Spec = Sync?aid?a?b?c?bid:diff(TypeThreadID,{aid})!b!a!c ?cid:diff(TypeThreadID,{aid,bid})!c!a!b -> Spec
\end{minted}

There are two test cases. The first test case involves three threads. Each of the thread chooses a data non-deterministically and then calls one of \textbf{aSync}, \textbf{bSync}, \textbf{cSync}. The second test case involves four thread, which chooses a data non-deterministically and calls \textbf{aSync}. In both cases, the systems should be traced refined (is it this direction in words) by the specification process. In addition, both systems should never deadlock, and the communication should continue forever.

When testing with both the correct and the faulty versions of ABC object, FDR finishes the first test case relatively quickly, but requires a long time to finish the second test. With logging message from FDR, it was found compilation of specification process took the longest time. 

\subsubsection{Speeding up model compilation}
Consider the specification process. Let $N$ be the number of threads in the system, $M$ be the size of the data set. The specification process is the alphabetized parallel of $N$ individual linearizes. In each linearizer, the process first chooses to perform one of \textbf{aSync}, \textbf{bSync} or \textbf{cSync}, chooses the argument of the functional call for \textbf{Call} event, then chooses the rest of arguments for \textbf{Sync} event, and finally performs one event before recursing into itself.

There are $3*M^9$ different transitions before the individual linearizer recurses into itself, but only $3*M^3$ transitions are valid according to the specification. 

\begin{minted}[breaklines]{haskell}
    Call!me!ASync?a ->
    Sync!me!a?b?c ?t2:diff(All,{me})?t2b?t2a?t2c ?t3:diff(All,{me,t2})?t3c?t3a?t3b ->
    Return!me!ASync!b!c ->
    Lin(All,me)
\end{minted}
    
With the above analysis, it is tempting to optimize the individual linearizer by using the information from the specification process. Instead of choosing all possible remaining arguments, the individual linearizer could choose arguments that are correct according to the specification process.

\begin{minted}[breaklines]{haskell}
    Sync!me!a?b?c ?t2:diff(All,{me})!b!a!c ?t3:diff(All,{me,t2})!c!a!b ->
    Return!me!ASync!b!c
\end{minted}
It is possible to further simplify the \textbf{Sync} channel, as now the arguments representing return value are redundant. This change does not reduce the number of transitions for an individual linearizer, but it may help FDR simulating the model faster.

With the above optimizations, the testing finishes quickly for both test cases.

//TOADD: Table of compilation time

\subsubsection{Explanation of the error case}
With the traces of the counterexample from FDR, it is possible to see what goes wrong in the faulty version when there are four threads.

//TODO: Draw diagram using Scala code for this.
\begin{itemize}
    \item Thread \textbf{TA}, \textbf{TB}, \textbf{TC} call \textbf{aSync}, \textbf{bSync} or \textbf{cSync} respectively, and put down its argument.
    \item Thread \textbf{TA} raises \textbf{bSignal} without saving a copy of return value {(b,c)}. The other two threads \textbf{TB}, \textbf{TC} are able to continue and exit. 
    \item Thread \textbf{TD}, \textbf{TB}, \textbf{TC} call \textbf{aSync}, \textbf{bSync} or \textbf{cSync} respectively, and put down its argument.
    \item Thread \textbf{TA} uses the wrong overwritten \textbf{(b,c)} as return value. 
\end{itemize}


\end{document}