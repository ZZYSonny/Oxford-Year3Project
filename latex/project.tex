\documentclass[a4paper, 12pt]{article}
\usepackage{cite}
\usepackage{listing}
\usepackage{csp}
\usepackage{cspm}
\usepackage{helper}
\usepackage{adjustbox}
\makeatletter
\AtBeginDocument{%
  \let\c@figure\c@lstlisting
  \let\thefigure\thelstlisting
  \let\ftype@lstlisting\ftype@figure % give the floats the same precedence
}
\makeatother
\renewcommand\floatpagefraction{0.1}

\begin{document}
Abstract

Concurrent objects are convenient tools for programmers. With concurrent objects, programmers can write code with multiple threads as if they are writing a single-threaded code. However, it is crucial to know the correctness of concurrent objects. In this thesis, we study a technique to justify the correctness of synchronization objects. We first present CSP models for common concurrent primitive according to their behaviours. We then systematically build several concurrent objects from their Scala sources. We make assertions of these synchronization objects with a technique derived from linearizability testing. We find these assertions can effectively find bugs in a concurrent datatype and provide a history to give more context for the developer. 

\newpage


\tableofcontents
\newpage

\section{Introduction}
%What is a concurrent datatype
Concurrent objects are convenient tools for programmers. With concurrent datatypes, programmers can write code with multiple threads as if they are writing a single-threaded code. However, it is crucial to know the correctness of concurrent objects. If the implementation of a concurrent object is wrong, then code using the concurrent object is very likely to be faulty. 

The \CSPM{Channel} object is one synchronization object commonly used in Go. The channel object can be used to share data from one process to another process. A process can send data to another process by calling \CSPM{send} with the data to share. Likewise, a process can receive data from other processes by calling \CSPM{receive} function. In Go and Communicating Scala Object package, the channels are unbuffered by default. If there is no process to receive the data, the sending process blocks until a process is willing to receive its data. Similarly, a receiving process blocks until a process sends some data. 

\begin{scalainline}{menwomen.scala.interface}{Interface of a MenWomen object}
trait Channel{
  def send(data: Int): Int
  def receive(): Int
}
\end{scalainline}

In this thesis, we shall study the correctness of synchronization objects. Each synchronization in a synchronization object involves multiple processes, whereas synchronization in concurrent datatypes like concurrent queue and concurrent only involves a single process. 

There are two main properties to check for a synchronization object, the safety property and the liveness property. The safety property states that the history of the synchronization object should satisfy some conditions. For example, if one process sends $1$ when no other process is sending, then a process calling \CSPM{receive} should only receive $1$. The liveness property states that the concurrent object should not refuse to synchronize when synchronization is possible between one or more processes. For example, if a process calls \CSPM{send} and a process \CSPM{receive}, the system should be able to synchronize and should not deadlock. 

\subsection{Thesis Overview}
In the remaining part of Section 1, we describe the correctness condition for a synchronization object and abstractly how to test these conditions in CSP using the linearization test technique. 

In section 2, we build CSP modules for common concurrent primitives such as shared variables, monitors and semaphores.

Starting from section 3, we use the linearization test technique to distinguish between correct and faulty implementation for several synchronization objects. We first implement the synchronization object in CSP according to its Scala source code. Then we write specifications for a system using the synchronization object and carry out the tests.

\subsection{Synchronization linearizability test}
%Describe lin point
To verify the correctness of a concurrent datatype, one can carry out the linearizability test described in the paper Testing for Linearizability \cite{linearizability-testing}. The linearizability testing framework logs the orders of each function call and function return. Then for the observed history, the testing framework attempt to find a series of synchronization point that obeys the safety property. The concurrent datatype implementation is considered faulty if the framework can not find a valid synchronization point series. 

In this remaining section, we shall look at a few examples of histories of systems using the \CSPM{Channel} object. Figure \ref{chan.timeline.simple} visualizes the history of a system with two processes. Process \CSPM{T1} calls \CSPM{send} with argument $1$ and returns. Process \CSPM{T2} calls \CSPM{receive} and returns with $1$. Each long horizontal line in the timeline represents a function call made by the corresponding process. The short vertical bars at the two ends of the long horizontal line indicate the function call's starting time and ending time. And the long vertical line between \CSPM{T1} and \CSPM{T2} represents the synchronization between the two processes. 

\svginline{chan.timeline.simple}{Visualized history of T1 calling send(1) and T2 calling receive()}

Figure \ref{chan.timeline.faulty} shows a timeline similar to Figure \ref{chan.timeline.simple}, but \CSPM{T2} returns $2$ instead of $1$. In this case, the linearizability test framework can not justify the return of process{T2}'s \CSPM{receive}, and suggests the trace is generated by a faulty channel implementation. 
\svginline{chan.timeline.faulty}{Visualized history of T1 sends 1 but T2 receives 2}

In Figure \ref{chan.timeline.dead}, both processes calls \CSPM{send}, and no synchronization is possible. Note that the liveness condition is not invalidated even if the system deadlocks in this case.
\svginline{chan.timeline.dead}{Visualized history of both T1 and T2 calling send}

Scheduling is one of the reasons validating a history can be complicated. In Figure \ref{chan.timeline.deschedule}, process \CSPM{T3} calls \CSPM{send(3)} first but gets descheduled. Then \CSPM{T1} calls \CSPM{send(1)} and synchronizes with \CSPM{T2} which later calls \CSPM{receive}. The linearization framework usually needs to search a large state to find a valid series of synchronization points. 
\svginline{chan.timeline.deschedule}{Visualized history of T3 get descheduled}

\subsection{Checking safety property using CSP} 
The history observed by the linearizability framework can be captured as a trace in CSP. A \CSPM{Call} event in CSP represents the start of a function call in the observed history. A \CSPM{Return} event represents the returning of a function call. For the safety property, we check that set of all possible histories of a testing system is a subset of all correct histories. In CSP, this corresponds to an assertion that a testing system trace refines a specification of systems using the synchronization object. 

A generic and scalable system is used as the testing system. Each process in the testing system can call any function from the concurrent object with any arguments allowed. Each process must be allowed to terminate. Otherwise, the testing system only models a system that runs forever, given that there is no deadlock. We shall see how this affects bug finding in a concurrent datatype in later objects.

The specification process is constructed using the linearization technique. On the high level, the specification process for the system internally uses \CSPM{Sync} events to represent synchronization between processes. Inside the specification process, some sub-processes generate corresponding \CSPM{Call} and \CSPM{Return} event for every synchronization point. When all sub-processes are placed in parallel, the \CSPM{Sync} event agrees. So the resulting specification system generates all possible histories. 

We shall see a concrete implementation of a testing system and a specification process in the MenWomen section. 

\subsection{Checking liveness property using CSP}
For liveness property, we check the same generic and scalable testing system refines the same specification process, but in the failure model. One could use a datatype-specific specification process that does not explicitly use any synchronization points. However, reusing the linearizer process is easier. 

\subsection{Related work}
Testing for Linearizability \cite{linearizability-testing} presents a framework to test concurrent datatypes. However, because the testing framework uses observations of histories, it is unlikely to exhaust all possible histories of a system.

In Chapter 19 of Understanding Concurrent Systems \cite{ucs-book}, the author describes a CSP model for shared variables and provides a tool to analyze shared variable programs. But the tool lacks support for objects frequently used in concurrent programming, such as monitors and semaphores.

There are also runtime programming tools to detect race conditions and deadlocks in concurrent code. Thread Sanitizer \cite{threadsanitizer} detects race conditions and deadlocks in C++ and Go.
\section{Common Objects}
\subsection{Shared Variable}
The usage of shared variables is common in concurrent datatypes. For example, some concurrent datatypes may temporarily store the identity of a waiting process. However, CSP is more like a functional programming language and does not support mutable variables. 

A recursive process in CSP can capture the behaviour of a shared variable. The recursive process holds the value of the variable in its parameter. At any time, the variable process is willing to answer a query for the variable value in channel \CSPM{getValue}. Alternatively, the process can receive an update on the variable value in channel \CSPM{getValue}, after which the function recurses with the new variable value.

Because it is natural for a concurrent datatype to use multiple shared variables, the global variable is implemented as a CSP module in Figure \ref{globalvar.csp} to allow better code reuse. The module requires two parameters. \CSPM{TypeValue} is the set of possible values for the variable, and \CSPM{initialValue} is the value before any process modifies the variable. An uninitialized variable module is also available in the same Figure \ref{globalvar.csp}, with the only difference that the variable non-deterministically chooses an initial value from \CSPM{TypeValue} at start time. \CSPM{runWith} is a convenient helper function to run a given process \CSPM{P} with the \CSPM{Var} process. If the parameter \CSPM{hide} is true, \CSPM{runWith} function hides all events introduced by the shared variable. In later chapters, we will see how the \CSPM{runWith} function helps reduce the code complexity of the synchronization object implementation.

\begin{cspfloat}{globalvar.csp}{The shared variable module in CSP}
--set of possible value for the variable
--inital value for the variable
module ModuleVariable(TypeValue, initialValue)
  Var(value) = getValue!value -> Var(value)
             [] setValue?value -> Var(value)
  chanset = {|getValue, setValue|}
exports
  --(Bool, Proc) -> Proc
  runWith(hide,P) = if hide then (Var(initialValue) [|chanset|] P) \ chanset
                            else  Var(initialValue) [|chanset|] P
  channel getValue, setValue: TypeValue
endmodule

module ModuleUninitVariable(TypeValue)
  Var(value) = getValue!value -> Var(value)
            [] setValue?value -> Var(value)
  chanset = {|getValue, setValue|}
exports
  runWith(hide,P) = 
    if hide then ((|~| x:TypeValue @ Var(x)) [| chanset |] P) \ chanset
    else (|~| x:TypeValue @ Var(x)) [| chanset |] P
  channel getValue, setValue: TypeValue
endmodule
\end{cspfloat}

Figure \ref{globalvar.csp.example} is an example of two processes using a shared variable. The first line in the example creates a shared variable \CSPM{VarA} with value ranging from $0$ to $2$ and initialized with $0$. Process \CSPM{P} increments \CSPM{VarA} modulo $3$ forever and process \CSPM{Q} reads \CSPM{VarA} forever. Process \CSPM{P} interleaves with process \CSPM{Q}, and the combined process is further synchronized with the variable \CSPM{VarA} process. In the resulting process \CSPM{System}, changes to \CSPM{VarA} made by process \CSPM{P} is visible to process \CSPM{Q}.

\begin{cspinline}{globalvar.csp.example}{Example of two processes using a shared variable}
instance VarA = ModuleVariable({0..2},0)
P = VarA::getValue?a -> VarA::setValue!((a+1)%3) -> P
Q = VarA::getValue?a -> Q
System = VarA::runWith(false,P|||Q)
\end{cspinline}


\subsection{Semaphore}
A Semaphore is a simple but powerful concurrent primitive. This thesis shall describe and use a simplified binary semaphore from [TODO: Reference], which removes interrupts and timeout operations. 

A binary semaphore can either be raised or lowered. A \CSPM{up} function call raises the semaphore regardless of the semaphore state. If a process calls the \CSPM{down} method when the semaphore is raised, the semaphore becomes lowered. However, if the semaphore is unraised, the process waits until another process calls \CSPM{up} and proceeds to put down the semaphore. Depending on the initial state of the semaphore, a binary semaphore can be further categorized as a mutex semaphore or a signalling semaphore.

Modelling a semaphore is straightforward in CSP. Figure \ref{semaphore.csp} is the CSP semaphore module. A process may call \CSPM{up} function or \CSPM{down} function via channel \CSPM{upChan} or channel \CSPM{downChan} respectively. The semaphore is modelled by a process implemented by two mutually recursive functions \CSPM{Semaphore(True)} and \CSPM{Semaphore(False)}. The semaphore process representing an unraised state accepts a \CSPM{upChan} event by any process and proceeds to the raised process. The semaphore process representing a raised state can either accept a \CSPM{upChan} event and recurse to the raised process, or accept a \CSPM{downChan} event and proceed to the unraised process.

Like the shared variable in the earlier subsection, the semaphore is encapsulated in a CSP module. To create a semaphore, one needs to supply two arguments. \CSPM{TypeThreadID} is the set of identities of processes that use this semaphore. \CSPM{initialState} is a boolean value indicating the starting state of the semaphore. If \CSPM{initialState} is true, the semaphore is raised initially. Otherwise, the semaphore is lowered. 
\begin{cspfloat}{semaphore.csp}{The binary semaphore module in CSP}
module ModuleSemaphore(TypeThreadID, initialState)
  --Raised
  Semaphore(True) = downChan?id -> Semaphore(False)
                   [] upChan?id -> Semaphore(True)
  --Unraised
  Semaphore(False)= upChan?id   -> Semaphore(True)
  
  chanset = {|upChan, downChan|}
exports
  --runWith::(Bool,Proc) -> Proc
  runWith(hide,P) = (Semaphore [| chanset |] P) \ 
                     (if hide then chanset else {})
  channel upChan, downChan: TypeThreadID
endmodule
\end{cspfloat}

\subsection{Monitor}
\subsubsection{JVM Monitor}
A Monitor is another powerful concurrent primitive. This thesis will also use a simplified monitor from [TODO:reference]. JVM Monitor provides two key features, mutual exclusion and waiting. 

Monitors can be used to prevent race conditions. At any time, only one process can run code inside a synchronized block that belongs to one monitor. The function \CSPM{op1} in Figure \ref{monitor.scala.example} uses synchronized block to prevent race condition on variable $a$. 

Inside a \CSPM{synchronized} block, the process can also perform \CSPM{wait}, \CSPM{notify}, and \CSPM{notifyAll}. When a process inside the synchronized block calls \CSPM{wait}, the process suspends and waits for notification from other processes. Since a waiting process may be spurious waked up, so a \CSPM{wait} call is used with a while loop and a condition. In the MoniorExample of Figure \ref{monitor.scala.example}, \CSPM{op2} waits until there is 10 \CSPM{op1} calls. In \CSPM{op1}, a process calls \CSPM{notifyAll} after incrementing the shared variale \CSPM{a}. When there aren't 10 \CSPM{op1} calls, process waiting in \CSPM{op2} first wakes, finds the condition $a<10$ true, and returns to sleep. 


\begin{scalainline}{monitor.scala.example}{A simple Scala class that uses a monitor internally}
class MonitorExample {
  private var a = 0;

  def op1():Unit = synchronized{ 
    a=(a+1)%20; 
    notifyAll()
  }
  def op2():Unit = synchronized{ 
    while(a<10) wait();
  }
}
\end{scalainline}
  
\subsubsection{Monitor Module}
The monitor process has two states and behaves differently in two states, captured by two processes in Figure \ref{monitor.csp.1}.

When there is no running process, the behaviour of the monitor is captured by the CSP process \CSPM{inactive}, with parameter \CSPM{waiting} being the set of waiting processes. The monitor can allow a process to run synchronized code with a \CSPM{waitEnter} event. Or, the monitor can spuriously wake a process with a \CSPM{SpuriousWake} event, and the spuriously waken process behaves like a normally waken process.

When there is a running process, the behaviour of the monitor is captured by the CSP process \CSPM{active}, with parameter \CSPM{cur} being the identity of the process running \CSPM{synchronized} block, and \CSPM{waiting} being the set of the waiting process. The monitor process should respond to method calls from the running process \CSPM{cur}, and the monitor should not allow another process to obtain the monitor lock. In \CSPM{active} state, the monitor can also spuriously wake a waiting process. 

On the client process side, most functions are implemented by simply synchronizing with the monitor on an event. For example, before entering the \CSPM{synchronized} block, the process sends a \CSPM{WaitEnter} event. The only exception is the \CSPM{wait} function, as after being notified, the process needs to resume execution. The process first sends a \CSPM{wait} event to tell the monitor that it is waiting and release the monitor lock. The monitor then receives a \CSPM{waitNotify} or \CSPM{spuiousWake} event, for being notified. Then the process reobtains the monitor lock with a \CSPM{waitEnter} event. 

The monitor module also provides a few useful macros. The \CSPM{synchronized} function wraps a CSP code to run under the protection of the monitor. The \CSPM{whilewait} function implements the common Scala pattern `while(cond) wait()`. The implementation uses a functional replacement for \CSPM{while} statement in imperative programming languages. The \CSPM{cond} parameter is a CSP function of type `(Proc, Proc) -> Proc`. The return process of \CSPM{cond} first performs some events to check the condition of the while statement. If the condition is true, the return process continues to run the process in the first parameter, or the return process runs the process in the second parameter.

With these process side functions and macros, the Scala MonitorExample class in Figure \ref{monitor.scala.example} can be converted into the CSP code in Figure \ref{monitor.csp.example}.

\begin{cspinline}{monitor.csp.example}{The CSP implementation of MonitorExample}
instance VarA = ModuleVariable({0..20},0)
instance Monitor = ModuleMonitor(TypeThreadID, False)

op1(me)=synchronized(me,
  --a=(a+1)%20; 
  VarA::getValue?x -> VarA::setValue!((x+1)%20) ->
  --notifyAll();
  Monitor::notifyAll(me)
)

op2(me)=synchronized(me,
  --while(a<10) wait()
  Monitor::whileWait(me, \ktrue,kfalse @
    VarA::getValue?x -> if x<10 then ktrue else kfalse
  )
)
\end{cspinline}
  

There are two design choices worth mentioning in the implementation of the monitor. 

First, note that both \CSPM{WaitNotify} and \CSPM{SpuriousWake} events come from the monitor process instead of directly synchronizing with the currently running process. When a process calls \CSPM{notify} or \CSPM{notifyAll}, it needs to synchronize with the monitor process. This is because the running process does not know how many processes are waiting. If the monitor is implemented the other way, the notifying process will block if there is no waiting process. Similarly, a process calling \CSPM{notifyAll} does not know how many processes it should wake up. 

Secondly, a monitor can introduce divergence by repetitively spuriously waking up a waiting process, whose condition keeps unsatisfied and never changes. This is an unwanted behaviour in failure testing. So the monitor module has an extra parameter \CSPM{disableSpurious} to disable spurious wakeups. 


\begin{cspfloat}{monitor.csp.1}{The CSP Monitor Module - Part 1 - the monitor process}
module ModuleMonitor(TypeThreadID, disableSpurious)
  channel Notify, NotifyAll, Exit, Wait, 
          WaitNotify, WaitEnter, SpuriousWake: TypeThreadID

  chanset = {| Notify, NotifyAll, Exit, Wait, WaitNotify, WaitEnter, SpuriousWake|}

  --A list of event for every event e in s
  repeat(ch, s) = if s=={} then SKIP else ch?a:s -> repeat(ch, diff(s, {a}))

  --cur is current active running thread
  --waiting is a set of threads waiting to be notified
  active(cur, waiting) =
    --current running thread notify
    Notify.cur -> (
      --do nothing if no thread is waiting
      if waiting=={} then active(cur, {})
      --wakeup a process
      else WaitNotify?a:waiting -> 
           active(cur, diff(waiting, {a}))
    ) [] --current running thread notifyAll
    NotifyAll.cur -> (
      repeat(WaitNotify, waiting);
      active(cur, {})
    ) [] --current running thread exit
    Exit.cur -> (
      inactive(waiting)
    ) [] --current running thread wait
    Wait.cur -> (
      inactive(union(waiting,{cur}))
    ) [] --spurious wakeup
    waiting!={} & SpuriousWake?a:waiting -> (
      active(cur, diff(waiting, {a}))
    )

  --when no active thread is running
  inactive(waiting) = 
    --pick a thread that is ready to enter
    WaitEnter?a -> (
      active(a, waiting)
    ) []
    --spurious wakeup
    waiting!={} & SpuriousWake?a:waiting -> (
      inactive(diff(waiting, {a}))
    )
\end{cspfloat}

\begin{cspfloat}{monitor.csp.2}{The CSP Monitor Module - Part 2 - client process side functions}
exports
  --Given a process that uses the monitor
  --Return the process synchronized with the monitor server process
  --If hide is true, monitor channels are hidden
  runWith(hideSpurious, hideInternal, P) = 
    let hideset0 = if hideInternal then chanset else {} within
    let hideset1 = if hideSpurious then hideset0 
                   else diff(hideset0,{|SpuriousWake|}) within
    (inactive({}) [|chanset|] P) \ hideset1
  
  --java-like synchronized function
  synchronized(me, P)= WaitEnter.me -> P; Exit.me -> SKIP

  enter(me) = WaitEnter.me -> SKIP

  exit(me) = Exit.me -> SKIP

  --notify()
  notify(me) = Notify.me -> SKIP

  --notifyAll()
  notifyAll(me) = NotifyAll.me -> SKIP

  --wait()
  wait(me) =
    Wait.me -> 
    if disableSpurious then (
      (WaitNotify.me -> WaitEnter.me -> SKIP)
   [] (SpuriousWake.me -> WaitEnter.me -> SKIP)
  ) else (
      (WaitNotify.me -> WaitEnter.me -> SKIP)
  )
  
  whileWait(me,cond) = while(cond)(wait(me);SKIP)
endmodule
\end{cspfloat}

\newpage
\section{MenWomen}
The MenWomen object is a classical problem from the concurrent programming course. In the problem, some processes need to pair off and share identities between the paired processes. Figure \ref{menwomen.scala.interface} is the interface of the MenWomen object. A process can call \CSPM{manSync} from the object to pair with a process calling \CSPM{womanSync}. Also a process can call \CSPM{womanSync} from the object to pair with another process calling \CSPM{manSync}. For simplicity, if a process is calling \CSPM{manSync}, we shall call it a man process. Similarly, a process calling \CSPM{manSync} is called a woman process.

\begin{scalainline}{menwomen.scala.interface}{Scala Interface of the MenWomen object}
trait MenWomenT{
  def manSync(me: Int): Int
  def womanSync(me: Int): Int
}
\end{scalainline}

\subsection{Implementation}
One way to implement the MenWomen object is to use a monitor and a shared variable indicating the stage of synchronization. Figure \ref{menwomen.scala.correct} is a Scala implementation of the MenWomen object with monitor.
\begin{itemize}
  \item A man process enters the synchronization and waits until the current stage is $0$. Then in stage $0$, the man process sets the global variable \CSPM{him} inside the \CSPM{MenWomen} object to its identity. Then the man process notifies all processes so that a waiting woman process can continue. Finally, the man process waits for stage 2.
  \item A women process enters the synchronization and waits until the current stage is $1$. The woman process sets the global variable \CSPM{her} to its identity and returns the value of the global variable \CSPM{him}.
  \item In stage $2$, the waiting man process in stage $0$ is wakened up by the woman process in stage $1$. The man process notifies all waiting processes and returns the value of \CSPM{her}.
\end{itemize}

The code snippet in Figure \ref{menwomen.scala.correct} is a Scala implementation of the MenWomen process using a monitor by Gavin Lowe. With the shared variable and monitor module, the Scala code is further translated to a CSP code in Figure \ref{menwomen.csp.correct}. With the convention described in the introduction section, every function call begins with a Call event containing all parameters. And every function call ends with a Return event containing the return value.

\begin{scalafloat}{menwomen.scala.correct}{A correct MenWomen object implementation in Scala}
class MenWomen extends MenWomenT{
  private var stage = 0
  private var him = -1
  private var her = -1

  def manSync(me: Int): Int = synchronized{
    while(stage != 0) wait()         
    him = me; stage = 1; notifyAll() 
    while(stage != 2) wait()
    stage = 0; notifyAll(); her
  }

  def womanSync(me: Int): Int = synchronized{
    while(stage != 1) wait()
    her = me; stage = 2; notifyAll();
  }
}
\end{scalafloat}

\begin{cspfloat}{menwomen.csp.correct}{Translated CSP code for the correct MenWomen object immplementation}
instance VarStage = ModuleVariable({0,1,2},0) 
instance VarHim = ModuleUninitVariable(TypeThreadID)
instance VarHer = ModuleUninitVariable(TypeThreadID)
instance Monitor = ModuleMonitor(TypeThreadID)
manSync(me) = 
  Call!me!ManSync ->
  Monitor::enter(me);
    Monitor::whileWait(me, \ktrue,kfalse @
      VarStage::getValue?x ->
      if x!=0 then ktrue else kfalse
    );
    VarHim::setValue!me ->
    VarStage::setValue!1 ->
    Monitor::notifyAll(me);
    Monitor::whileWait(me, \ktrue,kfalse @
      VarStage::getValue?x ->
      if x!=2 then ktrue else kfalse
    );
    VarStage::setValue!0 ->
    Monitor::notifyAll(me);
    VarHer::getValue?ans ->(
  Monitor::exit(me);
  Return!me!ManSync!ans->
  SKIP
  )
womanSync(me)=
  Call!me!WomanSync ->
  Monitor::enter(me);
    Monitor::whileWait(me, \ktrue,kfalse @
      VarStage::getValue?x ->
      if x!=1 then ktrue else kfalse
    );
    VarHer::setValue!me ->
    VarStage::setValue!2 ->
    Monitor::notifyAll(me);
    VarHim::getValue?ans ->(
  Monitor::exit(me);
  Return!me!WomanSync!ans->
  SKIP
  )
\end{cspfloat}


\subsection{Linearization Test}
Recall that in the testing system, each process can call any function provided by the concurrent datatype or choose to terminate. In defining processes in the testing system, a helper function is used. \CSPM{chaosP(P)} runs the process \CSPM{P} forever or terminates after running a finite number of \CSPM{P}. The processes in the testing system simply use \CSPM{chaosP} with a process that non deterministically chooses to perform \CSPM{manSync} or \CSPM{womanSync} with their identities. 

\begin{cspinline}{helper.chaosP}{Definition of helper function chaosP and processes in the testing system}
chaosP(P) = (P;chaosP(P)) |~| SKIP
Thread(me)=chaosP(manSync(me) |~| womanSync(me))
\end{cspinline}
  
All processes in the testing system interleave with other processes and synchronize with the processes of shared variables and the process of the monitor. Since the testing system should only include \CSPM{Call} and \CSPM{Return} events, all other events are hidden using the first two boolean flags in \CSPM{runWith} defined in earlier sections. 

\begin{cspinline}{menwomen.csp.testsystem}{Definition of CSP processes in the testing system}
System(All)=runWith(True,True,||| me:All @ Thread(me))
\end{cspinline}

Figure \ref{menwomen.csp.sync} is the definition and specification of \CSPM{Sync} event used internally in the testing specification. A \CSPM{Sync} event takes four parameters, the identity of the man process, the return value of the man process, the identity of the woman process, the return value of the woman process. For each synchronization, we check two properties. First, synchronization occurs between two different processes. Second, the return value of each participating process is the identity of the other participating process. 

\begin{cspinline}{menwomen.csp.sync}{Definition of Sync channel}
channel Sync: TypeThreadID.TypeThreadID.TypeThreadID.TypeThreadID
Spec = Sync?man?woman!woman:diff(TypeThreadID,{man})!man -> Spec
\end{cspinline}

A linearizer process alone generates all possible \CSPM{Call} and \CSPM{Return} events with \CSPM{Sync} events in between given the identity of process. For \CSPM{MenWomen} object, the linearizer is implemented with three non-deterministic choice branches, shown in Figure \ref{menwomen.csp.lin}. In the first branch, the linearizer calls \CSPM{manSync}, synchronize with another linearizer process calling \CSPM{womanSync}, and returns with the identity it received from the \CSPM{Sync} event. In the second branch, the linearizer performs \CSPM{womanSync}. In the last branch, the linearizer terminates. This construction ensures two properties: the return value of a function call comes from the synchronization, and the synchronization point occurs sometime during the function call. 

\CSPM{Linearizers(All)} creates a linearizer process for every process and puts these linearizers in parallel using replicated generalized parallel in CSPM. By the semantic of the replicated generalized parallel, when a process wants to perform an event, the process must synchronize all other processes which can perform this event. In the case of \CSPM{MenWomen}, when a linearizer for \CSPM{T1} wishes to perform a \CSPM{Call} or a \CSPM{Return} event, the linearizer does not need to synchronize with any processes because no linearizer can call using others' identity. However, when \CSPM{linearizer(T1)} wishes to perform a \CSPM{Sync} event such as \CSPM{Sync.T1.T2.T2.T1}, \CSPM{linearizer(T1)} needs to synchronize with \CSPM{linearizer(T2)} because the latter process can perform this \CSPM{Sync} event. Such construction ensures one more property: a \CSPM{Sync} event must be performed by corresponding processes at the same time. The combined process is then put to run in parallel with specification for the \CSPM{Sync} event, shown earlier in Figure \ref{menwomen.csp.sync}, to ensure all \CSPM{Sync} event represents valid synchronizations. Finally, like the testing system, all \CSPM{Sync} events are hidden, leaving \CSPM{Call} and \CSPM{Return} in \CSPM{Linearizers}.

Figure \ref{menwomen.lin.simple} visualizes trace generated by \CSPM{Linearizers({T1,T2})} in a FDR way. When a linearizer performs \CSPM{Call} and \CSPM{Return}, the linearizer does not synchronize with any process. When \CSPM{linearizer(T1)} performs \CSPM{Sync.T1.T2.T2.T1}, \CSPM{linearizer(T2)} and \CSPM{Spec} must also perform the \CSPM{Sync} event.

\svginline{menwomen.lin.simple}{FDR Visualization of traces of a man process and a woman process synchronizing}

Figure \ref{menwomen.lin.dead} is another FDR visualization of traces generated by \CSPM{Linearizers}. In this example, all two linearizers choose to call \CSPM{manSync} and no \CSPM{Sync} event is possible between the two linearizers.

\svginline{menwomen.lin.dead}{FDR Visualization of traces of two man processes deadlocking}

All above properties suffice to show that \CSPM{Linearizers(All)} generates all traces that correspond to a valid history and that \CSPM{Linearizers} is a valid specification process for the testing system. Informally, for any valid history, a linearizability test can find a set of synchronization points, which corresponds to a trace of the specification for \CSPM{Sync} events. Furthermore, the valid history can be obtained by adding respective call and return events around synchronization points. 

Finally, we perform the test using trace refinement for safety property and failure refinement for liveness. As expected, the correct implementation passes all tests. 
\begin{cspinline}{menwomen.csp.test}{Part of liveness and safetyness test in CSP for MenWomen object}
System2=System({T1,T2})
Spec2Thread=Linearizers({T1,T2})
assert Spec2Thread [T= System2
assert Spec2Thread [F= System2
\end{cspinline}

\begin{cspfloat}{menwomen.csp.lin}{Definition of linearizer process in CSP}
Lin(All,me)= (
  Call!me!ManSync->
  Sync!me?mereturn?other?otherreturn ->
  Return!me!ManSync!mereturn ->
  Lin(All,me)
)|~|(
  Call!me!WomanSync ->
  Sync?other?otherreturn!me?mereturn ->
  Return!me!WomanSync!mereturn ->
  Lin(All,me)
)|~|STOP

LinEvents(All,me)=union({
  ev | ev<-{|Sync|},
  let Sync.t1.a.t2.b=ev within
    countList(me,<t1,t2>)==1 and
    member(t1, All) and
    member(t2, All)
},{|Call.me,Return.me|})

Linearizers(All)=((|| me: All @ [LinEvents(All,me)] Lin(All,me)) [|{|Sync|}|] Spec) 
                  \{|Sync|}
\end{cspfloat}

\subsection{A faulty version}
We shall examine another MenWomen implementation in Figure \ref{menwomen.scala.faulty}. One key difference in this faulty MenWomen object is that it uses \CSPM{Option} data in the shared variables to store the identity of the process calling \CSPM{manSync} and the process calling \CSPM{womanSync}. 

\begin{scalafloat}{menwomen.scala.faulty}{A Faulty Scala implementation of MenWomen object}
class FaultyMenWomen extends MenWomenT{
  private var him: Option[Int] = None
  private var her: Option[Int] = None

  def manSync(me: Int): Int = synchronized{
    while(him.nonEmpty) wait()
    him = Some(me); notifyAll()
    while(her.isEmpty) wait()   
    val Some(res) = her
    her = None; notifyAll()
    res
  }

  def womanSync(me: Int): Int = synchronized{
    while(her.nonEmpty) wait()
    her = Some(me); notifyAll()
    while(him.isEmpty) wait()  
    val Some(res) = him
    him = None; notifyAll()
    res
  }
}
\end{scalafloat}

The safeness property test shows that this implementation handles scheduling carelessly. This implementation fails the test \CSPM{Spec2Thread [T= System2}, and FDR provides a trace that violates the safeness specification, shown in Figure \ref{menwomen.faulty.trace}. FDR further allows the user to expand the hidden $\tau$ events in the testing system, which are normally processes' interactions with shared variables and the monitor. By understanding the expanded trace in CSP, we can find a equivalent way to trigger the bug in Scala.

\svginlinescaled{menwomen.faulty.trace}{0.95}{Trace}

\begin{itemize}
  \item A process \CSPM{T1} calls \CSPM{manSync}. On first line, since the shared variable \CSPM{him} is initially \CSPM{None}, \CSPM{T1} skips the \CSPM{wait}, set \CSPM{him} to \CSPM{Some(T1)} and waits for a process calling \CSPM{womanSync}.
  \item A process \CSPM{T2} calls \CSPM{womanSync} and returns \CSPM{T1}. At this stage, there is no waiting process waiting to run \CSPM{womanSync} and the shared variable is not \CSPM{None}. So \CSPM{T2} does not wait at any point, notifies all waiting process, and returns.
  \item Before \CSPM{T1} reenters the \CSPM{synchronized} block, process \CSPM{T2} calls \CSPM{womanSync} again. \CSPM{him} has not been reset by \CSPM{T1} yet. So \CSPM{T2} pairs with \CSPM{T1} again, which should not be allowed. 
\end{itemize}

\newpage
\section{ABC}
With an ABC object, three processes can exchange data with each other two processes. More specifically, one process calling \CSPM{aSync}, one process calling \CSPM{bSync}, and one process calling \CSPM{cSync} synchronizes. Then each of the three processes returns with the arguments of two other processes. For simplicity, we shall call a process calling \CSPM{syncA} as an A-process, a process calling \CSPM{syncB} as a B-process, and a process calling \CSPM{syncC} as a C-process. 

One of the challenges to check an ABC object is the huge number of states in the CSP model. In this section, we shall see how the linearizer process can be optimized and the efficiency of the explicit linearization point test.

\subsection{Implementation}
Figure \ref{abc.scala.correct} is a Scala implementation of a ABC object with semaphore. In each round of synchronization,
\begin{itemize}
    \item Initially semaphore \CSPM{aClear} is raised. An A-process acquires semaphore \CSPM{aClear}, sets the shared variable \CSPM{a} to its parameter, raises semaphore \CSPM{bClear} and waits to acquire semaphore \CSPM{aSignal}. A B-process and a C-process behaves similarly in turn, except they use different semaphores and shared variables. 
    \item After a C-process raises semaphore \CSPM{aSignal}, the A-process is able to continue. The A-process reads the shared variable \CSPM{b} and \CSPM{c}, raises the semaphore \CSPM{bSignal}, and returns \CSPM{b} and \CSPM{c}. Likewise, B and C also take the value of two other shared variable and raise respective semaphores in turn.
\end{itemize}

Using the shared variable and semaphore module, it is easy to translate the Scala implementation to a CSP implementation.

\begin{scalafloat}{abc.scala.correct}{A semaphore-based Scala implementation of the ABC object}
class ABC[A,B,C] extends ABCT[A,B,C]{
  // The identities of the current (or previous) threads.
  private var a: A = _
  private var b: B = _
  private var c: C = _

  // Semaphores to signal that threads can write their identities.
  private val aClear = MutexSemaphore()
  private val bClear, cClear = SignallingSemaphore()

  // Semaphores to signal that threads can collect their results. 
  private val aSignal, bSignal, cSignal = SignallingSemaphore()

  def syncA(me: A) = {
    aClear.down         // (A1)
    a = me; bClear.up   // signal to b at (B1)
    aSignal.down        // (A2)
    val result = (b,c)
    bSignal.up          // signal to b at (B2)
    result
  }

  def syncB(me: B) = {
    bClear.down         // (B1)
    b = me; cClear.up   // signal to C at (C1)
    bSignal.down        // (B2)
    val result = (a,c)
    cSignal.up          // signal to c at (C2)
    result
  }

  def syncC(me: C) = {
    cClear.down         // (C1)
    c = me; aSignal.up  // signal to A at (A2)
    cSignal.down        // (C2)
    val result = (a,b)
    aClear.up           // signal to an A on the next round at (A1)
    result
  }
}      
\end{scalafloat}

\begin{cspfloat}{abc.csp.correct}{Translated CSP Code for the correct ABC implementation}
instance VarA = ModuleUninitVariable(TypeData) 
instance VarB = ModuleUninitVariable(TypeData)
instance VarC = ModuleUninitVariable(TypeData)

instance aClear = ModuleMutexSemaphore(TypeThreadID)
instance bClear = ModuleSignallingSemaphore(TypeThreadID)
instance cClear = ModuleSignallingSemaphore(TypeThreadID)
instance aSignal = ModuleSignallingSemaphore(TypeThreadID)
instance bSignal = ModuleSignallingSemaphore(TypeThreadID)
instance cSignal = ModuleSignallingSemaphore(TypeThreadID)

runWith(hide,p)=
  VarA::runWith(hide,
  VarB::runWith(hide,
  VarC::runWith(hide,
  aClear::runWith(hide,
  bClear::runWith(hide,
  cClear::runWith(hide,
  aSignal::runWith(hide,
  bSignal::runWith(hide,
  cSignal::runWith(hide,
    p
  )))))))))

SyncA(me,avalue) =
  Call!me!ASync!avalue ->
  --aClear.down
  aClear::downChan!me ->
  --a = me
  VarA::setValue!avalue ->
  --bClear.up
  bClear::upChan!me ->
  --aSignal.down
  aSignal::downChan!me ->
  --(b,c)
  VarB::getValue?b ->
  VarC::getValue?c ->
  --bSignal.up
  bSignal::upChan!me ->
  --result ->
  Return!me!ASync!(b.c) ->
  SKIP

...
\end{cspfloat}

\subsection{Testing}
Similar for the MenWomen object, a testing system is defined through any number of working processes and a specification is built from a \CSPM{Sync} channel, linearizer processes, and a synchronization alphabet set. 

One key difference of the \CSPM{ABC} object is that processes can call with any argument from the set \CSPM{TypeData}, whereas in \CSPM{MenWomen} object, processes can only call with their identity. As shown in Figure \ref{abc.csp.worker} So inside \CSPM{chaosP}, the processes also choose an argument with General Non-Deterministic Choice. 

\begin{cspinline}{abc.csp.worker}{Definition of processes in the testing system.}
Thread(me)=chaosP( |~| x:TypeData @ (
    SyncA(me,x) 
  |~| SyncB(me,x) 
  |~| SyncC(me,x)
))
\end{cspinline}

The testing specification uses the same component, the \CSPM{Sync} channel, linearizer processes, and linEventns. The definition of \CSPM{Sync} channel is shown in Figure \ref{abc.csp.sync}. The event $Sync.t_1.a.b.c.t_2.d.e.f.t_3.g.h.i$ represents the synchronizations between three threads, $t_1,t_2,t_3$. Process $t_1$ calls \CSPM{aSync} with $a$ and returns $(b,c)$. The second process $t_2$ calls \CSPM{bSync} with $d$ and returns $(e,f)$. And the last process $t_3$ calls \CSPM{cSync} with $g$ and returns $(h,i)$. The Sync specification process, shown in the same figure, checks that in each \CSPM{Sync} events, the return value of each process is the pair of arguments of the two other function call. 

Figure \ref{abc.csp.lin} is the definition of a linearizer process, written a similar format with the MenWomen object.

\begin{cspinline}{abc.csp.sync}{Definition of Sync channel and specification of Sync event}
--thread identity calling ASync. ASync parameter a. ASync return pair (b,c)
--thread identity calling BSync. BSync parameter b. BSync return pair (a,c)
--thread identity calling CSync. CSync parameter c. CSync return pair (a,b)
channel Sync: TypeThreadID.TypeData.TypeData.TypeData.
              TypeThreadID.TypeData.TypeData.TypeData.
              TypeThreadID.TypeData.TypeData.TypeData

Spec = Sync?aid?a?b?c
           ?bid:diff(TypeThreadID,{aid})!b!a!c
           ?cid:diff(TypeThreadID,{aid,bid})!c!a!b 
    -> Spec
\end{cspinline}

\begin{cspfloat}{abc.csp.lin}{Definition of linearizer process}
--Linearizer for a process
Lin(All,me)=(
  --me synchronizes as thread A
  Call!me!ASync?a ->
  Sync!me!a?b?c?t2:diff(All,{me})?t2b?t2a?t2c?t3:diff(All,{me,t2})?t3c?t3a?t3b ->
  Return!me!ASync!b!c ->
  Lin(All,me)
) |~| (
  --me synchronizes as thread B
  Call!me!BSync?b ->
  Sync?t2:diff(All,{me})?t2b?t2a?t2c!me!b?a?c?t3:diff(All,{me,t2})?t3c?t3a?t3b ->
  Return!me!BSync!a!c ->
  Lin(All,me)
) |~| (
  --me synchronizes as thread C
  Call!me!CSync?c ->
  Sync?t2:diff(All,{me})?t2b?t2a?t2c?t3:diff(All,{me,t2})?t3a?t3b!me!c?a?b ->
  Return!me!CSync!a!b ->
  Lin(All,me)
)
\end{cspfloat}

\begin{cspinline}{abc.csp.test}{Part of test for ABC object. This tests a system with three processes.}
System3=System({T1,T2,T3})
Spec3Thread=Linearizers({T1,T2,T3})

assert Spec3Thread [T= System3
assert Spec3Thread [F= System3
\end{cspinline}
\subsubsection{Speeding up model compilation}
Consider the specification process with three processes. Let $M$ be the size of the set of all possible arguments. Conside r the trace in Figure \ref{abc.timeline.lin}, where process \CSPM{T1} calls \CSPM{aSync} with \CSPM{A}, \CSPM{T2} calls \CSPM{bSync} with \CSPM{B}, \CSPM{T3} calls \CSPM{cSync} with \CSPM{C}. Then they synchronization.

\svginlinescaled{abc.timeline.lin}{0.95}{The set of possible Sync event for each CSP process}

The last transition in the diagram is the \CSPM{Sync} event between three processes. Above the edge is the set of possible \CSPM{Sync} event that every process accepts. Each linearizer accepts $3^2*M^8$ possible \CSPM{Sync} event. The combined linearizer accepts $M^6$ sync event. However, according to the sync specification, only one \CSPM{Sync} event is valid. 
    
With the above analysis, it is tempting to reduce the redundancy in \CSPM{Sync} event. Optimize the linearizer process by using the information from the specification process. Instead of choosing all possible remaining arguments, the individual linearizer could choose correct arguments according to the specification process. Figure \ref{abc.csp.simple1} includes part of the simplified code. This change does not reduce the number of transitions in the resulting specification, but it helps FDR build the process faster.

With this optimization, the testing for less than 5 processes finishes quickly.

\begin{cspinline}{abc.csp.simple1}{Simplified definition of Sync channel and part of simplified linearizer}
channel Sync: TypeThreadID.TypeThreadID.TypeThreadID.
              TypeData.TypeData.TypeData

Lin(All,me)= (
  Call!me!ASync?a ->
  Sync!me?t2:diff(All,{me})?t3:diff(All,{me,t2})!a?b?c ->
  Return!me!ASync!b!c ->
  Lin(All,me)
) ...
\end{cspinline}

\subsection{Faulty version}
Recall that in Java and Scala, raising a semaphore immediately allows another thread waiting to acquire the semaphore to continue. So it is essential to take a copy of the two other arguments before raising the semaphore.

On the other hand, what if the implementation of \CSPM{syncA} does not take a copy of the argument? It turns out that the faulty \CSPM{ABC} object passes tests for three processes but fails the linearisation test with at least four threads.


\subsubsection{Explanation of the error case}
For the test \CSPM{Spec4Thread [T= System4}, FDR displays a trace of the testing system that violates the specification. From the trace, it seems that process \CSPM{T1} synchronizes with \CSPM{T2} and \CSPM{T3} in the first round, and should return \CSPM{(B,C)}, but \CSPM{(E,F)}, the argument in the second round is returned. Expanding the $\tau$ event and translating CSP traces into program traces makes it possible to see what goes wrong in the faulty version when there are four threads.

\svginlinescaled{abc.faulty.trace}{0.9}{Trace that violates the specification}

\begin{itemize}
  \item In the first round of synchronization, process $T_A$, $T_B$, $T_C$ call \CSPM{aSync}, \CSPM{bSync} or \CSPM{cSync} respectively, and put down its argument in turn.
  \item Process $T_A$ raises \CSPM{bSignal}. Before $T_A$ exits, the other two processes $T_B$, $T_C$ returns. Now $T_A$ should return argument of $T_B$ and $T_C$.
  \item Another round of synchronization starts. Thread $T_D$, $T_B$, $T_C$ call \CSPM{aSync}, \CSPM{bSync} or \CSPM{cSync} respectively, and overwites the shared variable \CSPM{a,b,c} in turn.
  \item Now $T_A$ returns with $(b,c)$ from the second round, which may not be the argument of \CSPM{bSync} and \CSPM{cSync} in the first round.
\end{itemize}

\section{Terminating Queue}
A terminating queue provides thread-safe enqueue and dequeue operations. If a process dequeues when the queue is empty, the process blocks and waits for some process to enqueue. In addition, if all processes dequeue when the queue is empty, the queue terminates and returns \CSPM{None}. Figure \ref{queue.scala.interface} is the interface of a terminating queue.

\begin{scalainline}{queue.scala.interface}{Scala interface of terminating queue}
trait TerminatingQueueT[A]{ 
  def enqueue(x: A): Unit
  def dequeue: Option[A] 
}
\end{scalainline}

A terminating queue is a stateful synchronization object, as earlier enqueue and dequeue operation affect later synchronizations. The first diagram below 

\subsection{Implementation}
The Scala implementation of the Terminating Queue wraps a Scala Queue with a monitor. Upon creation, the object is given the number of processes using the queue \CSPM{numWorkers}. In addition to a internal queue \CSPM{queue}, the terminating queue uses two more shared variables. The shared variable \CSPM{waiting} is the number of processes waiting to dequeue an element from the queue. The shared variable \CSPM{done} indicates if the queue has terminated. If the value of \CSPM{done} is false, then any further function call should do nothing.

Enqueue is a trivial operation. In the synchronized block, the process adds the element to the internal queue and notifies a process waiting to dequeue an element. Dequeuing is also trivial when the internal queue is not empty. The process simply perform dequeue on the internal queue. When the queue is empty, if the value of \CSPM{waiting} is $n-1$, then all processes are now waiting to dequeue, so the queue should terminate. The process notifies all waiting process and returns \CSPM{None}. Otherwise the process increments the counter \CSPM{waiting} and waits. The waiting process may be waken because a new element is added to the queue, all $n$ processes are waiting, and spurious wake up. In the first case, the process decrements \CSPM{waiting} and returns the queue head as normal. In the latter case, the process returns \CSPM{None}.

\begin{scalafloat}{queue.scala.impl}{Scala implementation of terminating queue}
class TerminatingQueue[A](numWorkers: Int){
  private val queue = new Queue[A]
  private var waiting = 0
  private var done = false

  def enqueue(x: A) = synchronized{ 
    if(!done){
      queue.enqueue(x)
      if(waiting > 0) notify()
    }
  }

  def dequeue: Option[A] = synchronized{
    if(!done && queue.isEmpty){
      if(waiting == numWorkers-1){  // System should terminate
        done = true; notifyAll() 
      }  
      else{
        waiting += 1
        while(queue.isEmpty && !done) wait()
        waiting -= 1
      }
    }
    if(done) None else Some(queue.dequeue)
  }
}
\end{scalafloat}

//6559

There are a few workarounds required for the CSP implementation, because the set of possible value should be finite so that the communication graph FDR computes is finite and analyzable. For this reason, the range of variable \CSPM{waiting} is limited to integers from 0 to \CSPM{numWorkers} inclusive. However, while building the communication graph, FDR attempts to set the value of \CSPM{waiting} to \CSPM{-1} and \CSPM{numWorkers+1} and errors. Even though the value of \CSPM{waiting} will never be \CSPM{-1} or \CSPM{numWorkers+1} in both the Scala implementation and CSP implementation, FDR is unable to derive such information while building the communication graph for one process. 

To workaround this, we guard \CSPM{waiting} settings with a if statement. A CSP process diverges if it attempts to set a value outside \CSPM{0} to \CSPM{numWorkers}. In the testing system, we check that system is divergence free to show that \CSPM{waiting} works as expected.

Second, the Scala implementation uses a Scala Queue internally, which does not have a capacity limit and results to a infinite choices of queues in CSP. To address this, we use two finite-state queues that captures some properties of a infinite queue. Both queue has extra restrictions on the enqueue operations. When the constraint is violated, the process \CSPM{STOP} or \CSPM{DIV} according to what is required in testing. Figure ref is the implementation of the two queue, and the two queue are written under the same interface to allow code reuse.

The first queue is a capacity-limited queue and tests , which blocks a process when a process tries to the queue has more element than capacity. The first queue tests traces where the size of queue never exceeds some number. 

The second queue is an infinite queue but it only allows enqueue operation in the form of A*BC*. The idea comes from [TODO:Reference] and a system with this queue tests that the terminating queue does not miss or duplicate an element in the queue. The transition of the queue is presented in Figure ref. If a process calls dequeue, the queue non deterministically chooses one dequeue outcome and returns to the process. For example, in the state \CSPM{A*B0C} where the queue has zero or more A, followed by one B and no C, the queue can non deterministically dequeue an A. Or the queue can choose to dequeue an B and transites the the state \CSPM{Q0C}.

\subsection{Linearization Testing}
We use similar approaches to construct the testing system and the specification. For the terminating queue object, there are three ways a process synchronizes using the object. When a process enqueues or dequeues, it synchronizes with the object and perform action on the internal queue. In the enqueue and dequeue case, the synchronization is represented by a Sync event with the identity of the process, an object representing the function call the return value. When the queue shutdowns and a process returns \CSPM{None}, the process synchronizes with all other processes. In this case, the synchronization is represented by \CSPM{SyncShutdown}. 

Since a terminating queue is a stateful synchronziation object, the specification of \CSPM{Sync} event is different with earlier \CSPM{Sync} specification. For both queue, the \CSPM{Sync} specification should ensure that elements are added and removed in a FIFO order, and all enqueue and dequeue operation are valid for the queue. \CSPM{Sync} specification does not check \CSPM{SyncShutdown} however. Because  In addition the \CSPM{Sync} specification should ensure no enqueue operation is allowed when the queue is full. For the second queue, the \CSPM{Sync} specification should ensure the element enqueued are in the form of A*BC*. Figure ref is the specification for the first queue, which is implemented by a process holding the queue in the paramemter. Figure ref is the specificatioon for the second queue. The specification is splitted to several phases, with \CSPM{Spec1} specifying the synchronization before B is added, \CSPM{Spec2} specifying synchronization before B is dequeued, \CSPM{Spec3} specifying the 

[TODO: Update Code]
Before testing the safetyness and liveness property, we check that the shared variable \CSPM{waiting} is actually in the range 0 to \CSPM{numWorkers}, by checking the testing system is divergence free when spurious wakeup are visible and invalid enqueue causes a process to \CSPM{STOP} instead of \CSPM{DIV}. For safetyness and liveness property, process diverges when they perform a invalid enqueue, so that they reject any operations
\subsection{Linerization Point Test}
sync for synchronization
1. sync event between call and return, call return agree
2. return match sync formal spec

Faulty1: Fails all test
Faulty2: Fails Failure refinement when spurious disabled
\documentclass[12pt,a4paper]{article}

\subsection{Faulty Implementation}
In this section we use the linearization test to distinguish the correct implementation with three faulty implementation of the terminating queue.  In the first faulty implementation, element \CSPM{A} is always added to the internal queue regardless of the parameter of enqueue function. In the second faulty implementation, \CSPM{enqueue} method does not use \CSPM{notify} to wake up waiting dequeueing processes. In the third implementation has a miss-by-one error. The termination condition becomes that value of \CSPM{waiting} is \CSPM{numWorkers} before incrementing the variable.   

The four implementation is tested under different combinations, and the result is listed in the table below.

\begin{adjustbox}{width=1\textwidth,center=\textwidth}
  \begin{tabular}{c c c c c c}
    \hline
    & Divergence Free & \multicolumn{2}{c}{Trace Refinement} & \multicolumn{2}{c}{Failure Test} \\ \hline
    & & Disable Spurious & Allow Spurious & Disable Spurious  & Allow Spurious  \\ \hline
    Correct & Pass & Pass & Pass & Pass & Pass \\ \hline
    Faulty1 & Pass & Fail & Fail & Fail & Fail \\ \hline
    Faulty2 & Pass & Fail & Pass & Fail & Pass \\ \hline
    Faulty3 & Pass & Fail & Pass & Fail & Pass \\ \hline
  \end{tabular}
\end{adjustbox}

With no surprise, the correct implementation passes all tests. The first faulty implementation fails all tests. The second faulty implementation fails only when spurious wakeup are disabled, as waiting processes can "coincidentally" spuriously wake up after one process enqueues. It shows that when testing a object that internally uses a monitor, one should test the object with spurious wake and without spurious wake. The third faulty implementation shows a similar pattern. With the new condition, the last process will not terminate the queue. As a result, all processes refuse to return. However, as spurious wakeups can cause divergence, the failure model is unable to capture this error. 

\section{Conclusion}
In the thesis we describe and apply linearization test to a number of synchronization objects, and these tests are able to distinguish correct and faulty implementation of the object. We also use explicit linearization point test and find explicit linearization points are faster because they do not use \CSPM{Call} and \CSPM{Return} event. We show optimize linearization test by reducing the redundancy in linearizer process and sync event. With all the knowledge we apply test to a complicated object. There are also more object we test for the project, but not presented in thesis. Interested readers can see the appendix section for the CSP code and assertion for these objects. 

Linearization test has some drawbacks. Limited by the complexity of testing system, the CSP model often use a different and smaller set of values compared to the actual implementation. For example, function converted from Scala synchronization object often accept a small set of data instead of the whole integer set. In the earlier section, the variable \CSPM{waiting} in terminating queue also used the exact range instead of the whole set of integer. This also applies to the number of processes in the system. When a system uses more than five processes, the refinement checking often takes a long time. However, a faulty system often fails at small scale and small ranges of values, so this is less likely to be a problem. 

Also, some of the synchronization object tested in the thesis are more like artificially created objects for concurrent teaching. For future work, one can build CSP models for concurrent and synchronization objects from Java source code. And a compiler from Java to CSP will benefit automatic testing of synchronization objects. 
\section{Reference}
\bibliographystyle{acm}
\bibliography{project}
\end{document}