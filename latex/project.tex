\documentclass{article}
\usepackage{cite}
\usepackage{listing}
\usepackage{csp}
\usepackage{cspm}
\usepackage{helper}

\makeatletter
\AtBeginDocument{%
  \let\c@figure\c@lstlisting
  \let\thefigure\thelstlisting
  \let\ftype@lstlisting\ftype@figure % give the floats the same precedence
}
\makeatother
\renewcommand\floatpagefraction{0.1}

\begin{document}
Summary

Concurrent objects are convenient tools for programmers. With concurrent objects, programmers can write code with multiple threads as if they are writing a single-threaded code. However, it is crucial to know the correctness of concurrent objects. In this thesis, we study a technique to justify the correctness of synchronization objects. We first present CSP models for common concurrent primitive according to their behaviours. We then systematically build several concurrent objects from their Scala sources. We make assertions of these synchronization objects with a technique derived from linearizability testing. We find these assertions can effectively find bugs in a concurrent datatype and provide a history to give more context for the developer. 

\newpage
\section{Introduction}
%What is a concurrent datatype
Concurrent objects are convenient tools for programmers. With concurrent datatypes, programmers can write code with multiple threads as if they are writing a single-threaded code. However, it is crucial to know the correctness of concurrent objects. If the implementation of a concurrent object is wrong, then code using the concurrent object is very likely to be faulty. 

The \CSPM{Channel} object is one synchronization object commonly used in Go. The channel object can be used to share data from one process to another process. A process can send data to another process by calling \CSPM{send} with the data to share. Likewise, a process can receive data from other processes by calling \CSPM{receive} function. In Go and Communicating Scala Object package, the channels are unbuffered by default. If there is no process to receive the data, the sending process blocks until a process is willing to receive its data. Similarly, a receiving process blocks until a process sends some data. 

\begin{scalainline}{menwomen.scala.interface}{Interface of a MenWomen object}
trait Channel{
  def send(data: Int): Int
  def receive(): Int
}
\end{scalainline}

In this thesis, we shall study the correctness of synchronization objects. Each synchronization in a synchronization object involves multiple processes, whereas synchronization in concurrent datatypes like concurrent queue and concurrent only involves a single process. 

There are two main properties to check for a synchronization object, the safety property and the liveness property. The safety property states that the history of the synchronization object should satisfy some conditions. For example, if one process sends $1$ when no other process is sending, then a process calling \CSPM{receive} should only receive $1$. The liveness property states that the concurrent object should not refuse to synchronize when synchronization is possible between one or more processes. For example, if a process calls \CSPM{send} and a process \CSPM{receive}, the system should be able to synchronize and should not deadlock. 

\subsection{Thesis Overview}
In the remaining part of Section 1, we describe the correctness condition for a synchronization object and abstractly how to test these conditions in CSP using the linearization test technique. 

In section 2, we build CSP modules for common concurrent primitives such as shared variables, monitors and semaphores.

Starting from section 3, we use the linearization test technique to distinguish between correct and faulty implementation for several synchronization objects. We first implement the synchronization object in CSP according to its Scala source code. Then we write specifications for a system using the synchronization object and carry out the tests.

\subsection{Synchronization linearizability test}
%Describe lin point
To verify the correctness of a concurrent datatype, one can carry out the linearizability test described in the paper Testing for Linearizability \cite{linearizability-testing}. The linearizability testing framework logs the orders of each function call and function return. Then for the observed history, the testing framework attempt to find a series of synchronization point that obeys the safety property. The concurrent datatype implementation is considered faulty if the framework can not find a valid synchronization point series. 

In this remaining section, we shall look at a few examples of histories of systems using the \CSPM{Channel} object. Figure \ref{chan.timeline.simple} visualizes the history of a system with two processes. Process \CSPM{T1} calls \CSPM{send} with argument $1$ and returns. Process \CSPM{T2} calls \CSPM{receive} and returns with $1$. Each long horizontal line in the timeline represents a function call made by the corresponding process. The short vertical bars at the two ends of the long horizontal line indicate the function call's starting time and ending time. And the long vertical line between \CSPM{T1} and \CSPM{T2} represents the synchronization between the two processes. 

\svginline{chan.timeline.simple}{Visualized history of T1 calling send(1) and T2 calling receive()}

Figure \ref{chan.timeline.faulty} shows a timeline similar to Figure \ref{chan.timeline.simple}, but \CSPM{T2} returns $2$ instead of $1$. In this case, the linearizability test framework can not justify the return of process{T2}'s \CSPM{receive}, and suggests the trace is generated by a faulty channel implementation. 
\svginline{chan.timeline.faulty}{Visualized history of T1 sends 1 but T2 receives 2}

In Figure \ref{chan.timeline.dead}, both processes calls \CSPM{send}, and no synchronization is possible. Note that the liveness condition is not invalidated even if the system deadlocks in this case.
\svginline{chan.timeline.dead}{Visualized history of both T1 and T2 calling send}

Scheduling is one of the reasons validating a history can be complicated. In Figure \ref{chan.timeline.deschedule}, process \CSPM{T3} calls \CSPM{send(3)} first but gets descheduled. Then \CSPM{T1} calls \CSPM{send(1)} and synchronizes with \CSPM{T2} which later calls \CSPM{receive}. The linearization framework usually needs to search a large state to find a valid series of synchronization points. 
\svginline{chan.timeline.deschedule}{Visualized history of T3 get descheduled}

\subsection{Checking safety property using CSP} 
The history observed by the linearizability framework can be captured as a trace in CSP. A \CSPM{Call} event in CSP represents the start of a function call in the observed history. A \CSPM{Return} event represents the returning of a function call. For the safety property, we check that set of all possible histories of a testing system is a subset of all correct histories. In CSP, this corresponds to an assertion that a testing system trace refines a specification of systems using the synchronization object. 

A generic and scalable system is used as the testing system. Each process in the testing system can call any function from the concurrent object with any arguments allowed. Each process must be allowed to terminate. Otherwise, the testing system only models a system that runs forever, given that there is no deadlock. We shall see how this affects bug finding in a concurrent datatype in later objects.

The specification process is constructed using the linearization technique. On the high level, the specification process for the system internally uses \CSPM{Sync} events to represent synchronization between processes. Inside the specification process, some sub-processes generate corresponding \CSPM{Call} and \CSPM{Return} event for every synchronization point. When all sub-processes are placed in parallel, the \CSPM{Sync} event agrees. So the resulting specification system generates all possible histories. 

We shall see a concrete implementation of a testing system and a specification process in the MenWomen section. 

\subsection{Checking liveness property using CSP}
For liveness property, we check the same generic and scalable testing system refines the same specification process, but in the failure model. One could use a datatype-specific specification process that does not explicitly use any synchronization points. However, reusing the linearizer process is easier. 

\subsection{Related work}
Testing for Linearizability \cite{linearizability-testing} presents a framework to test concurrent datatypes. However, because the testing framework uses observations of histories, it is unlikely to exhaust all possible histories of a system.

In Chapter 19 of Understanding Concurrent Systems \cite{ucs-book}, the author describes a CSP model for shared variables and provides a tool to analyze shared variable programs. But the tool lacks support for objects frequently used in concurrent programming, such as monitors and semaphores.

There are also runtime programming tools to detect race conditions and deadlocks in concurrent code. Thread Sanitizer \cite{threadsanitizer} detects race conditions and deadlocks in C++ and Go.
\section{Common Objects}
\subsection{Shared Variable}
The usage of shared variables is common in concurrent datatypes. For example, some concurrent datatypes may temporarily store the identity of a waiting process. However, CSP is more like a functional programming language and does not support mutable variables. 

A recursive process in CSP can capture the behaviour of a shared variable. The recursive process holds the value of the variable in its parameter. At any time, the variable process is willing to answer a query for the variable value in channel \CSPM{getValue}. Alternatively, the process can receive an update on the variable value in channel \CSPM{getValue}, after which the function recurses with the new variable value.

Because it is natural for a concurrent datatype to use multiple shared variables, the global variable is implemented as a CSP module in Figure \ref{globalvar.csp} to allow better code reuse. The module requires two parameters. \CSPM{TypeValue} is the set of possible values for the variable, and \CSPM{initialValue} is the value before any process modifies the variable. An uninitialized variable module is also available in the same Figure \ref{globalvar.csp}, with the only difference that the variable non-deterministically chooses an initial value from \CSPM{TypeValue} at start time. \CSPM{runWith} is a convenient helper function to run a given process \CSPM{P} with the \CSPM{Var} process. If the parameter \CSPM{hide} is true, \CSPM{runWith} function hides all events introduced by the shared variable. In later chapters, we will see how the \CSPM{runWith} function helps reduce the code complexity of the synchronization object implementation.

\begin{cspfloat}{globalvar.csp}{The shared variable module in CSP}
--set of possible value for the variable
--inital value for the variable
module ModuleVariable(TypeValue, initialValue)
  Var(value) = getValue!value -> Var(value)
             [] setValue?value -> Var(value)
  chanset = {|getValue, setValue|}
exports
  --(Bool, Proc) -> Proc
  runWith(hide,P) = if hide then (Var(initialValue) [|chanset|] P) \ chanset
                            else  Var(initialValue) [|chanset|] P
  channel getValue, setValue: TypeValue
endmodule

module ModuleUninitVariable(TypeValue)
  Var(value) = getValue!value -> Var(value)
            [] setValue?value -> Var(value)
  chanset = {|getValue, setValue|}
exports
  runWith(hide,P) = 
    if hide then ((|~| x:TypeValue @ Var(x)) [| chanset |] P) \ chanset
    else (|~| x:TypeValue @ Var(x)) [| chanset |] P
  channel getValue, setValue: TypeValue
endmodule
\end{cspfloat}

Figure \ref{globalvar.csp.example} is an example of two processes using a shared variable. The first line in the example creates a shared variable \CSPM{VarA} with value ranging from $0$ to $2$ and initialized with $0$. Process \CSPM{P} increments \CSPM{VarA} modulo $3$ forever and process \CSPM{Q} reads \CSPM{VarA} forever. Process \CSPM{P} interleaves with process \CSPM{Q}, and the combined process is further synchronized with the variable \CSPM{VarA} process. In the resulting process \CSPM{System}, changes to \CSPM{VarA} made by process \CSPM{P} is visible to process \CSPM{Q}.

\begin{cspinline}{globalvar.csp.example}{Example of two processes using a shared variable}
instance VarA = ModuleVariable({0..2},0)
P = VarA::getValue?a -> VarA::setValue!((a+1)%3) -> P
Q = VarA::getValue?a -> Q
System = VarA::runWith(false,P|||Q)
\end{cspinline}


\subsection{Semaphore}
A Semaphore is a simple but powerful concurrent primitive. This thesis shall describe and use a simplified binary semaphore from [TODO: Reference], which removes interrupts and timeout operations. 

A binary semaphore can either be raised or lowered. A \CSPM{up} function call raises the semaphore regardless of the semaphore state. If a process calls the \CSPM{down} method when the semaphore is raised, the semaphore becomes lowered. However, if the semaphore is unraised, the process waits until another process calls \CSPM{up} and proceeds to put down the semaphore. Depending on the initial state of the semaphore, a binary semaphore can be further categorized as a mutex semaphore or a signalling semaphore.

Modelling a semaphore is straightforward in CSP. Figure \ref{semaphore.csp} is the CSP semaphore module. A process may call \CSPM{up} function or \CSPM{down} function via channel \CSPM{upChan} or channel \CSPM{downChan} respectively. The semaphore is modelled by a process implemented by two mutually recursive functions \CSPM{Semaphore(True)} and \CSPM{Semaphore(False)}. The semaphore process representing an unraised state accepts a \CSPM{upChan} event by any process and proceeds to the raised process. The semaphore process representing a raised state can either accept a \CSPM{upChan} event and recurse to the raised process, or accept a \CSPM{downChan} event and proceed to the unraised process.

Like the shared variable in the earlier subsection, the semaphore is encapsulated in a CSP module. To create a semaphore, one needs to supply two arguments. \CSPM{TypeThreadID} is the set of identities of processes that use this semaphore. \CSPM{initialState} is a boolean value indicating the starting state of the semaphore. If \CSPM{initialState} is true, the semaphore is raised initially. Otherwise, the semaphore is lowered. 
\begin{cspfloat}{semaphore.csp}{The binary semaphore module in CSP}
module ModuleSemaphore(TypeThreadID, initialState)
  --Raised
  Semaphore(True) = downChan?id -> Semaphore(False)
                   [] upChan?id -> Semaphore(True)
  --Unraised
  Semaphore(False)= upChan?id   -> Semaphore(True)
  
  chanset = {|upChan, downChan|}
exports
  --runWith::(Bool,Proc) -> Proc
  runWith(hide,P) = (Semaphore [| chanset |] P) \ 
                     (if hide then chanset else {})
  channel upChan, downChan: TypeThreadID
endmodule
\end{cspfloat}

\subsection{Monitor}
\subsubsection{JVM Monitor}
A Monitor is another powerful concurrent primitive. This thesis will also use a simplified monitor from [TODO:reference]. JVM Monitor provides two key features, mutual exclusion and waiting. 

Monitors can be used to prevent race conditions. At any time, only one process can run code inside a synchronized block that belongs to one monitor. The function \CSPM{op1} in Figure \ref{monitor.scala.example} uses synchronized block to prevent race condition on variable $a$. 

Inside a \CSPM{synchronized} block, the process can also perform \CSPM{wait}, \CSPM{notify}, and \CSPM{notifyAll}. When a process inside the synchronized block calls \CSPM{wait}, the process suspends and waits for notification from other processes. Since a waiting process may be spurious waked up, so a \CSPM{wait} call is used with a while loop and a condition. In the MoniorExample of Figure \ref{monitor.scala.example}, \CSPM{op2} waits until there is 10 \CSPM{op1} calls. In \CSPM{op1}, a process calls \CSPM{notifyAll} after incrementing the shared variale \CSPM{a}. When there aren't 10 \CSPM{op1} calls, process waiting in \CSPM{op2} first wakes, finds the condition $a<10$ true, and returns to sleep. 


\begin{scalainline}{monitor.scala.example}{A simple Scala class that uses a monitor internally}
class MonitorExample {
  private var a = 0;

  def op1():Unit = synchronized{ 
    a=(a+1)%20; 
    notifyAll()
  }
  def op2():Unit = synchronized{ 
    while(a<10) wait();
  }
}
\end{scalainline}
  
\subsubsection{Monitor Module}
The monitor process has two states and behaves differently in two states, captured by two processes in Figure \ref{monitor.csp.1}.

When there is no running process, the behaviour of the monitor is captured by the CSP process \CSPM{inactive}, with parameter \CSPM{waiting} being the set of waiting processes. The monitor can allow a process to run synchronized code with a \CSPM{waitEnter} event. Or, the monitor can spuriously wake a process with a \CSPM{SpuriousWake} event, and the spuriously waken process behaves like a normally waken process.

When there is a running process, the behaviour of the monitor is captured by the CSP process \CSPM{active}, with parameter \CSPM{cur} being the identity of the process running \CSPM{synchronized} block, and \CSPM{waiting} being the set of the waiting process. The monitor process should respond to method calls from the running process \CSPM{cur}, and the monitor should not allow another process to obtain the monitor lock. In \CSPM{active} state, the monitor can also spuriously wake a waiting process. 

On the client process side, most functions are implemented by simply synchronizing with the monitor on an event. For example, before entering the \CSPM{synchronized} block, the process sends a \CSPM{WaitEnter} event. The only exception is the \CSPM{wait} function, as after being notified, the process needs to resume execution. The process first sends a \CSPM{wait} event to tell the monitor that it is waiting and release the monitor lock. The monitor then receives a \CSPM{waitNotify} or \CSPM{spuiousWake} event, for being notified. Then the process reobtains the monitor lock with a \CSPM{waitEnter} event. 

The monitor module also provides a few useful macros. The \CSPM{synchronized} function wraps a CSP code to run under the protection of the monitor. The \CSPM{whilewait} function implements the common Scala pattern `while(cond) wait()`. The implementation uses a functional replacement for \CSPM{while} statement in imperative programming languages. The \CSPM{cond} parameter is a CSP function of type `(Proc, Proc) -> Proc`. The return process of \CSPM{cond} first performs some events to check the condition of the while statement. If the condition is true, the return process continues to run the process in the first parameter, or the return process runs the process in the second parameter.

With these process side functions and macros, the Scala MonitorExample class in Figure \ref{monitor.scala.example} can be converted into the CSP code in Figure \ref{monitor.csp.example}.

\begin{cspinline}{monitor.csp.example}{The CSP implementation of MonitorExample}
instance VarA = ModuleVariable({0..20},0)
instance Monitor = ModuleMonitor(TypeThreadID, False)

op1(me)=synchronized(me,
  --a=(a+1)%20; 
  VarA::getValue?x -> VarA::setValue!((x+1)%20) ->
  --notifyAll();
  Monitor::notifyAll(me)
)

op2(me)=synchronized(me,
  --while(a<10) wait()
  Monitor::whileWait(me, \ktrue,kfalse @
    VarA::getValue?x -> if x<10 then ktrue else kfalse
  )
)
\end{cspinline}
  

There are two design choices worth mentioning in the implementation of the monitor. 

First, note that both \CSPM{WaitNotify} and \CSPM{SpuriousWake} events come from the monitor process instead of directly synchronizing with the currently running process. When a process calls \CSPM{notify} or \CSPM{notifyAll}, it needs to synchronize with the monitor process. This is because the running process does not know how many processes are waiting. If the monitor is implemented the other way, the notifying process will block if there is no waiting process. Similarly, a process calling \CSPM{notifyAll} does not know how many processes it should wake up. 

Secondly, a monitor can introduce divergence by repetitively spuriously waking up a waiting process, whose condition keeps unsatisfied and never changes. This is an unwanted behaviour in failure testing. So the monitor module has an extra parameter \CSPM{disableSpurious} to disable spurious wakeups. 


//Should I split some functions into respective paragraphs here. Or use line number. 
\begin{cspfloat}{monitor.csp.1}{The CSP Monitor Module - Part 1 - the monitor process}
module ModuleMonitor(TypeThreadID, disableSpurious)
  channel Notify, NotifyAll, Exit, Wait, 
          WaitNotify, WaitEnter, SpuriousWake: TypeThreadID

  chanset = {| Notify, NotifyAll, Exit, Wait, WaitNotify, WaitEnter, SpuriousWake|}

  --A list of event for every event e in s
  repeat(ch, s) = if s=={} then SKIP else ch?a:s -> repeat(ch, diff(s, {a}))

  --cur is current active running thread
  --waiting is a set of threads waiting to be notified
  active(cur, waiting) =
    --current running thread notify
    Notify.cur -> (
      --do nothing if no thread is waiting
      if waiting=={} then active(cur, {})
      --wakeup a process
      else WaitNotify?a:waiting -> 
           active(cur, diff(waiting, {a}))
    ) [] --current running thread notifyAll
    NotifyAll.cur -> (
      repeat(WaitNotify, waiting);
      active(cur, {})
    ) [] --current running thread exit
    Exit.cur -> (
      inactive(waiting)
    ) [] --current running thread wait
    Wait.cur -> (
      inactive(union(waiting,{cur}))
    ) [] --spurious wakeup
    waiting!={} & SpuriousWake?a:waiting -> (
      active(cur, diff(waiting, {a}))
    )

  --when no active thread is running
  inactive(waiting) = 
    --pick a thread that is ready to enter
    WaitEnter?a -> (
      active(a, waiting)
    ) []
    --spurious wakeup
    waiting!={} & SpuriousWake?a:waiting -> (
      inactive(diff(waiting, {a}))
    )
\end{cspfloat}

\begin{cspfloat}{monitor.csp.2}{The CSP Monitor Module - Part 2 - client process side functions}
exports
  --Given a process that uses the monitor
  --Return the process synchronized with the monitor server process
  --If hide is true, monitor channels are hidden
  runWith(hideSpurious, hideInternal, P) = 
    let hideset0 = if hideInternal then chanset else {} within
    let hideset1 = if hideSpurious then hideset0 else diff(hideset0,{|SpuriousWake|}) within
    (inactive({}) [|chanset|] P) \ hideset1
  
  --java-like synchronized function
  synchronized(me, P)= WaitEnter.me -> P; Exit.me -> SKIP

  enter(me) = WaitEnter.me -> SKIP

  exit(me) = Exit.me -> SKIP

  --notify()
  notify(me) = Notify.me -> SKIP

  --notifyAll()
  notifyAll(me) = NotifyAll.me -> SKIP

  --wait()
  wait(me) =
    Wait.me -> 
    if disableSpurious then (
      (WaitNotify.me -> WaitEnter.me -> SKIP)
   [] (SpuriousWake.me -> WaitEnter.me -> SKIP)
  ) else (
      (WaitNotify.me -> WaitEnter.me -> SKIP)
  )
  
  whileWait(me,cond) = while(cond)(wait(me);SKIP)
endmodule
\end{cspfloat}

\newpage
\section{MenWomen}
For simplicity, a process calling \CSPM{ManSync} is called a man process, and a process calling \CSPM{WomanSync} is called a woman process. 

\subsection{Implementation}
One way to implement the MenWomen object is to use a monitor and a shared variable indicating the stage of synchronization. Figure \ref{menwomen.scala.correct} is a Scala implementation of the MenWomen object with monitor.
\begin{itemize}
  \item A man process enters the synchronization and waits until the current stage is $0$. Then in stage $0$, the man process sets the global variable \CSPM{him} inside the \CSPM{MenWomen} object to its identity. Then the man process notifies all processes so that a waiting woman process can continue. Finally, the man process waits for stage 2.
  \item A women process enters the synchronization and waits until the current stage is $1$. The woman process sets the global variable \CSPM{her} to its identity and returns the value of the global variable \CSPM{him}.
  \item In stage $2$, the waiting man process in stage $0$ is wakened up by the woman process in stage $1$. The man process notifies all waiting processes and returns the value of \CSPM{her}.
\end{itemize}

The code snippet in Figure \ref{menwomen.scala.correct} is a Scala implementation of the MenWomen process using a monitor by Gavin Lowe. With the shared variable and monitor module, the Scala code is further translated to a CSP code in Figure \ref{menwomen.csp.correct}. With the convention described in the introduction section, every function call begins with a Call event containing all parameters. And every function call ends with a Return event containing the return value.

\begin{scalafloat}{menwomen.scala.correct}{A correct MenWomen object implementation in Scala}
class MenWomen extends MenWomenT{
  private var stage = 0
  private var him = -1
  private var her = -1

  def manSync(me: Int): Int = synchronized{
    while(stage != 0) wait()         
    him = me; stage = 1; notifyAll() 
    while(stage != 2) wait()
    stage = 0; notifyAll(); her
  }

  def womanSync(me: Int): Int = synchronized{
    while(stage != 1) wait()
    her = me; stage = 2; notifyAll();
  }
}
\end{scalafloat}

\begin{cspfloat}{menwomen.csp.correct}{Translated CSP code for the correct MenWomen object immplementation}
instance VarStage = ModuleVariable({0,1,2},0) 
instance VarHim = ModuleUninitVariable(TypeThreadID)
instance VarHer = ModuleUninitVariable(TypeThreadID)
instance Monitor = ModuleMonitor(TypeThreadID)
manSync(me) = 
  Call!me!ManSync ->
  Monitor::enter(me);
    Monitor::whileWait(me, \ktrue,kfalse @
      VarStage::getValue?x ->
      if x!=0 then ktrue else kfalse
    );
    VarHim::setValue!me ->
    VarStage::setValue!1 ->
    Monitor::notifyAll(me);
    Monitor::whileWait(me, \ktrue,kfalse @
      VarStage::getValue?x ->
      if x!=2 then ktrue else kfalse
    );
    VarStage::setValue!0 ->
    Monitor::notifyAll(me);
    VarHer::getValue?ans ->(
  Monitor::exit(me);
  Return!me!ManSync!ans->
  SKIP
  )
womanSync(me)=
  Call!me!WomanSync ->
  Monitor::enter(me);
    Monitor::whileWait(me, \ktrue,kfalse @
      VarStage::getValue?x ->
      if x!=1 then ktrue else kfalse
    );
    VarHer::setValue!me ->
    VarStage::setValue!2 ->
    Monitor::notifyAll(me);
    VarHim::getValue?ans ->(
  Monitor::exit(me);
  Return!me!WomanSync!ans->
  SKIP
  )
\end{cspfloat}


\subsection{Linearization Test}
Recall that in the testing system, each process can call any function provided by the concurrent datatype or choose to terminate. In the CSP implementation, a helper function is used. \CSPM{chaosP(P)} runs the process \CSPM{P} that terminate with \CSPM{SKIP} any number of time. With the helper function, the process \CSPM{P} only needs to non-deterministically choose to perform \CSPM{manSync} or \CSPM{womanSync} with its identity.

All processes in the testing system interleave with other processes and synchronize with the processes of shared variables and the process of the monitor. Since the testing system should only include \CSPM{Call} and \CSPM{Return} events, all other events are hidden using the first two boolean flags in \CSPM{runWith} defined in earlier sections. 

\begin{cspinline}{menwomen.csp.testsystem}{Definition of CSP processes in the testing system}
Thread(me)=chaosP(manSync(me) |~| womanSync(me))
System(All)=runWith(True,True,||| me:All @ Thread(me))
\end{cspinline}

Similarly, a linearizer process can non-deterministically choose to perform \CSPM{manSync}, synchronize with another linearizer process calling \CSPM{womanSync}, and return with the identity it received from the \CSPM{Sync} event. Also, the linearizer can choose to call \CSPM{womanSync} or terminate. \CSPM{Linearizers(All)} puts all linearizers processes in parallel. 

The \CSPM{Linearizers} function creates a combined linearizer process in three steps. First, it put all linearizer processes in parallel using Replicated Generalized Parallel in CSPM. Specifically,  General Parallel uses three arguments, the linearizer identity set, the linearizer process, and a synchronization alphabet set. The synchronization alphabet set for a process identity is the set of \CSPM{Sync} events where the process identity appears on the first or the third argument. If a linearizer process wants to send an event in its synchronization alphabet set, it must synchronize with all other linearizer processes whose synchronization alphabet sets include this event. 
Then \CSPM{Linearizers} runs the paralleled process with the specification process of \CSPM{Sync} event. For \CSPM{MenWomen} object, the synchronization is stateless and only requires the return value to be the identity of the other process.
Finally, like the testing system, all \CSPM{Sync} events are hidden to provide all valid histories.

\begin{cspfloat}{menwomen.csp.lin}{Definition of linearizer process in CSP}
Lin(All,me)= (
  Call!me!ManSync->
  Sync!me?mereturn?other?otherreturn ->
  Return!me!ManSync!mereturn ->
  Lin(All,me)
)|~|(
  Call!me!WomanSync ->
  Sync?other?otherreturn!me?mereturn ->
  Return!me!WomanSync!mereturn ->
  Lin(All,me)
)|~|STOP

LinEvents(All,me)=union({
  ev | ev<-{|Sync|},
  let Sync.t1.a.t2.b=ev within
    countList(me,<t1,t2>)==1 and
    member(t1, All) and
    member(t2, All)
},{|Call.me,Return.me|})

Linearizers(All)=((|| me: All @ [LinEvents(All,me)] Lin(All,me)) [|{|Sync|}|] Spec) 
                  \{|Sync|}
\end{cspfloat}

Figure \ref{menwomen.lin.simple} visualizes how the linearizer process can generate the trace that corresponds to the history described in Figure \ref{chan.timeline.simple}, where one process calls \CSPM{manSync} and another process calls \CSPM{womanSync}. And \ref{menwomen.lin.dead} visualizes the linearizer deadlocks as required if both processes calls \CSPM{manSync}.

\svginline{menwomen.lin.simple}{Linearizers generating the history where one process calls manSync and another process calling womenSync}
\svginline{menwomen.lin.dead}{Linearizers generating the history where one process calls manSync and another process calling womenSync}

Finally, we perform the test using trace refinement for safety property and failure refinement for liveness. As expected, the correct implementation passes all tests. 
\begin{cspinline}{menwomen.csp.test}{Part of liveness and safetyness test in CSP for MenWomen object}
System2=System({T1,T2})
Spec2Thread=Linearizers({T1,T2})
assert Spec2Thread [T= System2
assert Spec2Thread [F= System2
\end{cspinline}

\subsection{A faulty version}
We shall examine another MenWomen implementation in Figure \ref{menwomen.scala.faulty}. One key difference in this faulty MenWomen object is that it uses \CSPM{Option} data in the shared variables to store the identity of the process calling \CSPM{manSync} and the process calling \CSPM{womanSync}. 

\begin{scalafloat}{menwomen.scala.faulty}{A Faulty Scala implementation of MenWomen object}
class FaultyMenWomen extends MenWomenT{
  private var him: Option[Int] = None
  private var her: Option[Int] = None

  def manSync(me: Int): Int = synchronized{
    while(him.nonEmpty) wait()
    him = Some(me); notifyAll()
    while(her.isEmpty) wait()   
    val Some(res) = her
    her = None; notifyAll()
    res
  }

  def womanSync(me: Int): Int = synchronized{
    while(her.nonEmpty) wait()
    her = Some(me); notifyAll()
    while(him.isEmpty) wait()  
    val Some(res) = him
    him = None; notifyAll()
    res
  }
}
\end{scalafloat}

The safeness property test shows that this implementation handles scheduling carelessly. This implementation fails the test \CSPM{Spec2Thread [T= System2}, and FDR provides a trace that violates the safeness specification, shown in Figure \ref{menwomen.faulty.trace}. FDR further allows the user to expand the hidden $\tau$ events in the testing system, which are normally processes' interactions with shared variables and the monitor. By understanding the expanded trace in CSP, we can find a equivalent way to trigger the bug in Scala.

\svginlinescaled{menwomen.faulty.trace}{0.95}{Trace}

\begin{itemize}
  \item A process \CSPM{T1} calls \CSPM{manSync}. On first line, since the shared variable \CSPM{him} is initially \CSPM{None}, \CSPM{T1} skips the \CSPM{wait}, set \CSPM{him} to \CSPM{Some(T1)} and waits for a process calling \CSPM{womanSync}.
  \item A process \CSPM{T2} calls \CSPM{womanSync} and returns \CSPM{T1}. At this stage, there is no waiting process waiting to run \CSPM{womanSync} and the shared variable is not \CSPM{None}. So \CSPM{T2} does not wait at any point, notifies all waiting process, and returns.
  \item Before \CSPM{T1} reenters the \CSPM{synchronized} block, process \CSPM{T2} calls \CSPM{womanSync} again. \CSPM{him} has not been reset by \CSPM{T1} yet. So \CSPM{T2} pairs with \CSPM{T1} again, which should not be allowed. 
\end{itemize}

\newpage
\section{ABC}
With an ABC object, three processes can exchange data with each other two processes. More specifically, one process calling \CSPM{aSync}, one process calling \CSPM{bSync}, and one process calling \CSPM{cSync} synchronizes. Then each of the three processes returns with the arguments of two other processes. For simplicity, we shall call a process calling \CSPM{syncA} as an A-process, a process calling \CSPM{syncB} as a B-process, and a process calling \CSPM{syncC} as a C-process. 

One of the challenges to check an ABC object is the huge number of states in the CSP model. In this section, we shall see how the linearizer process can be optimized and the efficiency of the explicit linearization point test.

\subsection{Implementation}
Figure \ref{abc.scala.correct} is a Scala implementation of a ABC object with semaphore. In each round of synchronization,
\begin{itemize}
    \item Initially semaphore \CSPM{aClear} is raised. An A-process acquires semaphore \CSPM{aClear}, sets the shared variable \CSPM{a} to its parameter, raises semaphore \CSPM{bClear} and waits to acquire semaphore \CSPM{aSignal}. A B-process and a C-process behaves similarly in turn, except they use different semaphores and shared variables. 
    \item After a C-process raises semaphore \CSPM{aSignal}, the A-process is able to continue. The A-process reads the shared variable \CSPM{b} and \CSPM{c}, raises the semaphore \CSPM{bSignal}, and returns \CSPM{b} and \CSPM{c}. Likewise, B and C also take the value of two other shared variable and raise respective semaphores in turn.
\end{itemize}

Using the shared variable and semaphore module, it is easy to translate the Scala implementation to a CSP implementation.

\begin{scalafloat}{abc.scala.correct}{A semaphore-based Scala implementation of the ABC object}
class ABC[A,B,C] extends ABCT[A,B,C]{
  // The identities of the current (or previous) threads.
  private var a: A = _
  private var b: B = _
  private var c: C = _

  // Semaphores to signal that threads can write their identities.
  private val aClear = MutexSemaphore()
  private val bClear, cClear = SignallingSemaphore()

  // Semaphores to signal that threads can collect their results. 
  private val aSignal, bSignal, cSignal = SignallingSemaphore()

  def syncA(me: A) = {
    aClear.down         // (A1)
    a = me; bClear.up   // signal to b at (B1)
    aSignal.down        // (A2)
    val result = (b,c)
    bSignal.up          // signal to b at (B2)
    result
  }

  def syncB(me: B) = {
    bClear.down         // (B1)
    b = me; cClear.up   // signal to C at (C1)
    bSignal.down        // (B2)
    val result = (a,c)
    cSignal.up          // signal to c at (C2)
    result
  }

  def syncC(me: C) = {
    cClear.down         // (C1)
    c = me; aSignal.up  // signal to A at (A2)
    cSignal.down        // (C2)
    val result = (a,b)
    aClear.up           // signal to an A on the next round at (A1)
    result
  }
}      
\end{scalafloat}

\begin{cspfloat}{abc.csp.correct}{Translated CSP Code for the correct ABC implementation}
instance VarA = ModuleUninitVariable(TypeData) 
instance VarB = ModuleUninitVariable(TypeData)
instance VarC = ModuleUninitVariable(TypeData)

instance aClear = ModuleMutexSemaphore(TypeThreadID)
instance bClear = ModuleSignallingSemaphore(TypeThreadID)
instance cClear = ModuleSignallingSemaphore(TypeThreadID)
instance aSignal = ModuleSignallingSemaphore(TypeThreadID)
instance bSignal = ModuleSignallingSemaphore(TypeThreadID)
instance cSignal = ModuleSignallingSemaphore(TypeThreadID)

runWith(hide,p)=
  VarA::runWith(hide,
  VarB::runWith(hide,
  VarC::runWith(hide,
  aClear::runWith(hide,
  bClear::runWith(hide,
  cClear::runWith(hide,
  aSignal::runWith(hide,
  bSignal::runWith(hide,
  cSignal::runWith(hide,
    p
  )))))))))

SyncA(me,avalue) =
  Call!me!ASync!avalue ->
  --aClear.down
  aClear::downChan!me ->
  --a = me
  VarA::setValue!avalue ->
  --bClear.up
  bClear::upChan!me ->
  --aSignal.down
  aSignal::downChan!me ->
  --(b,c)
  VarB::getValue?b ->
  VarC::getValue?c ->
  --bSignal.up
  bSignal::upChan!me ->
  --result ->
  Return!me!ASync!(b.c) ->
  SKIP

...
\end{cspfloat}

\subsection{Testing}
Similar for the MenWomen object, a testing system is defined through any number of working processes and a specification is built from a \CSPM{Sync} channel, linearizer processes, and a synchronization alphabet set. 

One key difference of the \CSPM{ABC} object is that processes can call with any argument from the set \CSPM{TypeData}, whereas in \CSPM{MenWomen} object, processes can only call with their identity. As shown in Figure \ref{abc.csp.worker} So inside \CSPM{chaosP}, the processes also choose an argument with General Non-Deterministic Choice. 

\begin{cspinline}{abc.csp.worker}{Definition of processes in the testing system.}
Thread(me)=chaosP( |~| x:TypeData @ (
    SyncA(me,x) 
  |~| SyncB(me,x) 
  |~| SyncC(me,x)
))
\end{cspinline}

The testing specification uses the same component, the \CSPM{Sync} channel, linearizer processes, and linEventns. The definition of \CSPM{Sync} channel is shown in Figure \ref{abc.csp.sync}. The event $Sync.t_1.a.b.c.t_2.d.e.f.t_3.g.h.i$ represents the synchronizations between three threads, $t_1,t_2,t_3$. Process $t_1$ calls \CSPM{aSync} with $a$ and returns $(b,c)$. The second process $t_2$ calls \CSPM{bSync} with $d$ and returns $(e,f)$. And the last process $t_3$ calls \CSPM{cSync} with $g$ and returns $(h,i)$. The Sync specification process, shown in the same figure, checks that in each \CSPM{Sync} events, the return value of each process is the pair of arguments of the two other function call. 

Figure \ref{abc.csp.lin} is the definition of a linearizer process, written a similar format with the MenWomen object.

\begin{cspinline}{abc.csp.sync}{Definition of Sync channel and specification of Sync event}
--thread identity calling ASync. ASync parameter a. ASync return pair (b,c)
--thread identity calling BSync. BSync parameter b. BSync return pair (a,c)
--thread identity calling CSync. CSync parameter c. CSync return pair (a,b)
channel Sync: TypeThreadID.TypeData.TypeData.TypeData.
              TypeThreadID.TypeData.TypeData.TypeData.
              TypeThreadID.TypeData.TypeData.TypeData

Spec = Sync?aid?a?b?c
           ?bid:diff(TypeThreadID,{aid})!b!a!c
           ?cid:diff(TypeThreadID,{aid,bid})!c!a!b 
    -> Spec
\end{cspinline}

\begin{cspfloat}{abc.csp.lin}{Definition of linearizer process}
--Linearizer for a process
Lin(All,me)=(
  --me synchronizes as thread A
  Call!me!ASync?a ->
  Sync!me!a?b?c?t2:diff(All,{me})?t2b?t2a?t2c?t3:diff(All,{me,t2})?t3c?t3a?t3b ->
  Return!me!ASync!b!c ->
  Lin(All,me)
) |~| (
  --me synchronizes as thread B
  Call!me!BSync?b ->
  Sync?t2:diff(All,{me})?t2b?t2a?t2c!me!b?a?c?t3:diff(All,{me,t2})?t3c?t3a?t3b ->
  Return!me!BSync!a!c ->
  Lin(All,me)
) |~| (
  --me synchronizes as thread C
  Call!me!CSync?c ->
  Sync?t2:diff(All,{me})?t2b?t2a?t2c?t3:diff(All,{me,t2})?t3a?t3b!me!c?a?b ->
  Return!me!CSync!a!b ->
  Lin(All,me)
)
\end{cspfloat}

\begin{cspinline}{abc.csp.test}{Part of test for ABC object. This tests a system with three processes.}
System3=System({T1,T2,T3})
Spec3Thread=Linearizers({T1,T2,T3})

assert Spec3Thread [T= System3
assert Spec3Thread [F= System3
\end{cspinline}
\subsubsection{Speeding up model compilation}
Consider the specification process with three processes. Let $M$ be the size of the set of all possible arguments. Conside r the trace in Figure \ref{abc.timeline.lin}, where process \CSPM{T1} calls \CSPM{aSync} with \CSPM{A}, \CSPM{T2} calls \CSPM{bSync} with \CSPM{B}, \CSPM{T3} calls \CSPM{cSync} with \CSPM{C}. Then they synchronization.

\svginlinescaled{abc.timeline.lin}{0.95}{The set of possible Sync event for each CSP process}

The last transition in the diagram is the \CSPM{Sync} event between three processes. Above the edge is the set of possible \CSPM{Sync} event that every process accepts. Each linearizer accepts $3^2*M^8$ possible \CSPM{Sync} event. The combined linearizer accepts $M^6$ sync event. However, according to the sync specification, only one \CSPM{Sync} event is valid. 
    
With the above analysis, it is tempting to reduce the redundancy in \CSPM{Sync} event. Optimize the linearizer process by using the information from the specification process. Instead of choosing all possible remaining arguments, the individual linearizer could choose correct arguments according to the specification process. Figure \ref{abc.csp.simple1} includes part of the simplified code. This change does not reduce the number of transitions in the resulting specification, but it helps FDR build the process faster.

With this optimization, the testing for less than 5 processes finishes quickly.

\begin{cspinline}{abc.csp.simple1}{Simplified definition of Sync channel and part of simplified linearizer}
channel Sync: TypeThreadID.TypeThreadID.TypeThreadID.
              TypeData.TypeData.TypeData

Lin(All,me)= (
  Call!me!ASync?a ->
  Sync!me?t2:diff(All,{me})?t3:diff(All,{me,t2})!a?b?c ->
  Return!me!ASync!b!c ->
  Lin(All,me)
) ...
\end{cspinline}

\subsection{Faulty version}
Recall that in Java and Scala, raising a semaphore immediately allows another thread waiting to acquire the semaphore to continue. So it is essential to take a copy of the two other arguments before raising the semaphore.

On the other hand, what if the implementation of \CSPM{syncA} does not take a copy of the argument? It turns out that the faulty \CSPM{ABC} object passes tests for three processes but fails the linearisation test with at least four threads.


\subsubsection{Explanation of the error case}
For the test \CSPM{Spec4Thread [T= System4}, FDR displays a trace of the testing system that violates the specification. From the trace, it seems that process \CSPM{T1} synchronizes with \CSPM{T2} and \CSPM{T3} in the first round, and should return \CSPM{(B,C)}, but \CSPM{(E,F)}, the argument in the second round is returned. Expanding the $\tau$ event and translating CSP traces into program traces makes it possible to see what goes wrong in the faulty version when there are four threads.

\svginlinescaled{abc.faulty.trace}{0.9}{Trace that violates the specification}

\begin{itemize}
  \item In the first round of synchronization, process $T_A$, $T_B$, $T_C$ call \CSPM{aSync}, \CSPM{bSync} or \CSPM{cSync} respectively, and put down its argument in turn.
  \item Process $T_A$ raises \CSPM{bSignal}. Before $T_A$ exits, the other two processes $T_B$, $T_C$ returns. Now $T_A$ should return argument of $T_B$ and $T_C$.
  \item Another round of synchronization starts. Thread $T_D$, $T_B$, $T_C$ call \CSPM{aSync}, \CSPM{bSync} or \CSPM{cSync} respectively, and overwites the shared variable \CSPM{a,b,c} in turn.
  \item Now $T_A$ returns with $(b,c)$ from the second round, which may not be the argument of \CSPM{bSync} and \CSPM{cSync} in the first round.
\end{itemize}

\section{Barrier Counter}
Barrier synchronization is commonly used in concurrent programming ... A barrier object takes an argument $p$. A process calling \CSPM{sync} blocks until all \CSPM{p} processes call \CSPM{sync}. 

This section shall examine a barrier object with an internal counter. When a \CSPM{sync} call exits, it returns the number of times barrier synchronization has happened. 

\subsection{Implementation}

In this section, we shall use a monitor based barrier counter. Additionaly, this implementation uses three shared variables. \CSPM{seqNumber} is the number of synchronization that happened. \CSPM{count} is the number of processes participating in the current round of synchronization and is waiting to return. \CSPM{leaving} indicates if processes are leaving.

There are two stages in each round of synchronization. 
\begin{itemize}
    \item In the first stage, a new process comes and waits for all $p$ processes. Each process increments \CSPM{count}. 
    \item If a process finds the value of \CSPM{count} is $p$ after incrementing \CSPM{count}, the process knows it is the last process in this round. The $p$-th process sets leaving to \CSPM{true} and notifies all waiting processes to allow other processes in this round to leave and blocks any new coming processes. 
    \item In the second stage, all $p$ processes, including the $p$-th process, decrements \CSPM{count} to and returns with the value of the shared variable \CSPM{seqNumber}. 
    \item If a process finds the value of \CSPM{count} equal to $0$, then the process knows it is the last process to leave in this round. Before exiting, it increments \CSPM{seqNumber} and sets \CSPM{leaving} to \CSPM{true}, to allow a new round to start.
\end{itemize}

\begin{scalafloat}{barriercounter.scala.correct}{Implementation of Barrier Counter in Scala} 
class BarrierCounter(n: Int) extends BarrierCounterT{
  private var seqNumber = 0 // the current sequence number
  private var count = 0 // The number of waiting threads.
  private var leaving = false // Are we in the leaving phase?

  def sync = synchronized{
    while(leaving) wait() // Wait for previous round to finish
    count += 1
    if(count == n){ 
      leaving = true; 
      count -= 1; 
      notifyAll(); 
      seqNumber 
    } else{ 
      while(!leaving) wait()
      count -= 1
      if(count == 0){ 
        // Allow next round to continue
        leaving = false; 
        notifyAll() 
        // Increment sequence number for next round
        seqNumber += 1; 
        seqNumber-1 
      }
      else seqNumber
    }
  }
}  
\end{scalafloat}

\subsection{A stateful concurrent datatypes}
\newpage
\section{Terminating Queue}

\section{Reference}
\bibliographystyle{acm}
\bibliography{project}
\end{document}