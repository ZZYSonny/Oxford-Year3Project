\documentclass[a4paper, 12pt]{article}
\usepackage{cite}
\usepackage{listing}
\usepackage{csp}
\usepackage{cspm}
\usepackage{helper}
\usepackage{adjustbox}
\makeatletter
\AtBeginDocument{%
  \let\c@figure\c@lstlisting
  \let\thefigure\thelstlisting
  \let\ftype@lstlisting\ftype@figure % give the floats the same precedence
}
\makeatother
%\renewcommand\floatpagefraction{0.1}

\begin{document}
Abstract

Concurrent objects are convenient tools for programmers. With concurrent objects, programmers can write code with multiple threads as if they are writing a single-threaded code. However, it is crucial to know the correctness of concurrent objects. In this thesis, we study a technique to justify the correctness of synchronization objects. We first present CSP models for common concurrent primitives according to their behaviours. We then systematically build several concurrent objects from their Scala sources. We make assertions of these synchronization objects with a technique derived from linearizability testing. We find these assertions can effectively find bugs in a concurrent datatype and provide a history to give more context for the developer. 

\newpage


\tableofcontents
\newpage
\clearpage
\setcounter{page}{1}
\section{Introduction}
%What is a concurrent datatype
Concurrent objects are convenient tools for programmers. With concurrent datatypes, programmers can write code with multiple threads as if they are writing a single-threaded code. However, it is crucial to know the correctness of concurrent objects. If the implementation of a concurrent object is wrong, then code using the concurrent object is very likely to be faulty. 

The \CSPM{Channel} object is one synchronization object commonly used in Go. The channel object can be used to share data from one process to another process. A process can send data to another process by calling \CSPM{send} with the data to share. Likewise, a process can receive data from other processes by calling \CSPM{receive} function. In Go and Communicating Scala Object package, channels are unbuffered by default. If there is no process to receive the data, the sending process blocks until a process is willing to receive its data. Similarly, a receiving process blocks until a process sends some data. 

\begin{scalafloat}{menwomen.scala.interface}{Interface of a Channel object}
trait Channel{
  def send(data: Int): Int
  def receive(): Int
}
\end{scalafloat}

In this thesis, we shall study the correctness of synchronization objects. Each synchronization in a synchronization object involves multiple processes, whereas synchronization in concurrent datatypes like concurrent queue and concurrent only involves a single process. 

There are two main properties to check for a synchronization object, the safety property and the liveness property. The safety property states that the history of the synchronization object should satisfy some conditions. For example, if one process sends \CSPM{1} when no other process is sending, then a process calling \CSPM{receive} should only receive\CSPM{1}. The liveness property states that the concurrent object should not refuse to synchronize when synchronization is possible between one or more processes. For example, if a process calls \CSPM{send} and a process \CSPM{receive}, the system should be able to synchronize and should not deadlock. 

\subsection{Thesis Overview}
In the remaining part of Section 1, we describe the correctness condition for a synchronization object and abstractly how to test these conditions in CSP using the linearization test technique. 

In section 2, we build CSP modules for common concurrent primitives such as shared variables, monitors and semaphores.

Starting from section 3, we use the linearization test technique to distinguish correct and faulty implementation for several synchronization objects. We first implement the synchronization object in CSP according to its Scala source code. Then we write specifications for a system using the synchronization object and carry out the tests.

\subsection{Synchronization linearizability test}
%Describe lin point
To verify the correctness of a concurrent datatype, one can carry out the linearizability test described in the paper Testing for Linearizability \cite{linearizability-testing}. The linearizability testing framework logs the orders of each function call and function return. The testing framework then justifies the observed history by attempting to find a series of synchronization points that obey the safety property. The concurrent datatype implementation is considered faulty if the framework can not find a valid synchronization point series. 

In this remaining section, we shall look at a few examples of histories of systems using the \CSPM{Channel} object. Figure \ref{chan.timeline.simple} visualizes the history of a system with two processes. Process \CSPM{T1} calls \CSPM{send} with argument $1$ and returns. Process \CSPM{T2} calls \CSPM{receive} and returns with $1$. Each long horizontal line in the timeline represents a function call made by the corresponding process. The short vertical bars at the two ends of the long horizontal line indicate the function call's starting time and ending time. And the long vertical line between \CSPM{T1} and \CSPM{T2} represents the synchronization between the two processes. 

\svginline{chan.timeline.simple}{Visualized history of T1 calling send(1) and T2 calling receive()}

Figure \ref{chan.timeline.faulty} shows a timeline similar to Figure \ref{chan.timeline.simple}, but \CSPM{T2} returns $2$ instead of $1$. In this case, the linearizability test framework can not justify the return of process{T2}'s \CSPM{receive}, and suggests the trace is generated by a faulty channel implementation. 

\svginline{chan.timeline.faulty}{Visualized history of T1 sends 1 but T2 receives 2}

In Figure \ref{chan.timeline.dead}, both processes calls \CSPM{send}, and no synchronization is possible. Note that the liveness condition is not invalidated even if the system deadlocks in this case.

\svginline{chan.timeline.dead}{Visualized history of both T1 and T2 calling send}

Scheduling is one of the reasons validating a history can be complicated. In Figure \ref{chan.timeline.deschedule}, process \CSPM{T3} calls \CSPM{send(3)} first but gets descheduled. Then \CSPM{T1} calls \CSPM{send(1)} and synchronizes with \CSPM{T2} which later calls \CSPM{receive}. The linearization framework usually needs to search a large state space to find a valid series of synchronization points. 

\svginline{chan.timeline.deschedule}{Visualized history of T3 get descheduled}

\subsection{Checking safety property using CSP} 
The history observed by the linearizability framework can be captured as a trace in CSP. A \CSPM{Call} event in CSP represents the start of a function call in the observed history. A \CSPM{Return} event represents the returning of a function call. For the safety property, we check that set of all possible histories of a testing system is a subset of all correct histories. In CSP, this corresponds to an assertion that a testing system trace refines a specification of systems using the synchronization object. 

A generic and scalable system is used as the testing system. Each process in the testing system can call any function from the concurrent object with any arguments allowed. Each process must be allowed to terminate. Otherwise, the testing system only models a system that runs forever, given that there is no deadlock. We shall see how this affects bug finding in a concurrent datatype in later objects.

The specification process is constructed using the linearization technique. On the high level, the specification process for the system internally uses \CSPM{Sync} events to represent synchronization between processes. Inside the specification process, some sub-processes generate corresponding \CSPM{Call} and \CSPM{Return} event for every synchronization point. When all sub-processes are placed in parallel, the \CSPM{Sync} event agrees. So the resulting specification system generates all possible histories. 

We shall see a concrete implementation of a testing system and a specification process in the MenWomen section. 

\subsection{Checking liveness property using CSP}
For liveness property, we check the same generic and scalable testing system refines the same specification process, but in the failure model. One could use a datatype-specific specification process that does not explicitly use any synchronization points. However, reusing the linearizer process is easier. 

\subsection{Related work}
Testing for Linearizability \cite{linearizability-testing} presents a framework to test concurrent datatypes. As described in earlier subsections, the testing framework uses observations of histories and is unlikely to exhaust all possible histories of a system or check a infinite size history. However, the linearization test can exhaust all finite and infinite histories of a system using FDR's state machine. 

There are also runtime programming tools to detect race conditions and deadlocks in concurrent code. Thread Sanitizer \cite{threadsanitizer} detects race conditions and deadlocks in C++ and Go when the program is running. Like linearizability testing, runtime programming tools is unlikely to exhaust all possible histories. 

In Chapter 19 of Understanding Concurrent Systems \cite{ucs-book}, the author describes a CSP model for shared variables and provides a tool to analyze shared variable programs. This project further supports analyzing program using more synchronizations, such as monitor and semaphores.

\section{Common Objects}
\subsection{Shared Variable}
The usage of shared variables is common in concurrent datatypes. For example, some concurrent datatypes may temporarily store the identity of a waiting process. However, CSP is more like a functional programming language and does not support mutable variables. 

A recursive process in CSP can capture the behaviour of a shared variable. The recursive process holds the value of the variable in its parameter. At any time, the variable process is willing to answer a query for the variable value in channel \CSPM{getValue}. Alternatively, the process can receive an update on the variable value in channel \CSPM{getValue}, after which the function recurses with the new variable value.

Because it is natural for a concurrent datatype to use multiple shared variables, the global variable is implemented as a CSP module in Figure \ref{globalvar.csp} to allow better code reuse. The module requires two parameters. \CSPM{TypeValue} is the set of possible values for the variable, and \CSPM{initialValue} is the value before any process modifies the variable. An uninitialized variable module is also available in the same Figure \ref{globalvar.csp}, with the only difference that the variable non-deterministically chooses an initial value from \CSPM{TypeValue} at start time. \CSPM{runWith} is a convenient helper function to run a given process \CSPM{P} with the \CSPM{Var} process. If the parameter \CSPM{hide} is true, \CSPM{runWith} function hides all events introduced by the shared variable. In later chapters, we will see how the \CSPM{runWith} function helps reduce the code complexity of the synchronization object implementation.

\begin{cspfloat}{globalvar.csp}{The shared variable module in CSP}
--set of possible value for the variable
--inital value for the variable
module ModuleVariable(TypeValue, initialValue)
  Var(value) = getValue!value -> Var(value)
             [] setValue?value -> Var(value)
  chanset = {|getValue, setValue|}
exports
  --(Bool, Proc) -> Proc
  runWith(hide,P) = if hide then (Var(initialValue) [|chanset|] P) \ chanset
                            else  Var(initialValue) [|chanset|] P
  channel getValue, setValue: TypeValue
endmodule

module ModuleUninitVariable(TypeValue)
  Var(value) = getValue!value -> Var(value)
            [] setValue?value -> Var(value)
  chanset = {|getValue, setValue|}
exports
  runWith(hide,P) = 
    if hide then ((|~| x:TypeValue @ Var(x)) [| chanset |] P) \ chanset
    else (|~| x:TypeValue @ Var(x)) [| chanset |] P
  channel getValue, setValue: TypeValue
endmodule
\end{cspfloat}

Figure \ref{globalvar.csp.example} is an example of two processes using a shared variable. The first line in the example creates a shared variable \CSPM{VarA} with value ranging from $0$ to $2$ and initialized with $0$. Process \CSPM{P} increments \CSPM{VarA} modulo $3$ forever and process \CSPM{Q} reads \CSPM{VarA} forever. Process \CSPM{P} interleaves with process \CSPM{Q}, and the combined process is further synchronized with the variable \CSPM{VarA} process. In the resulting process \CSPM{System}, changes to \CSPM{VarA} made by process \CSPM{P} is visible to process \CSPM{Q}.

\begin{cspfloat}{globalvar.csp.example}{Example of two processes using a shared variable}
instance VarA = ModuleVariable({0..2},0)
P = VarA::getValue?a -> VarA::setValue!((a+1)%3) -> P
Q = VarA::getValue?a -> Q
System = VarA::runWith(false,P|||Q)
\end{cspfloat}


\subsection{Semaphore}
A Semaphore is a simple but powerful concurrent primitive. This thesis shall describe and use a simplified binary semaphore from \cite{CPinJava}, which removes interrupts and timeout operations. 

A binary semaphore can either be raised or lowered. A \CSPM{up} function call raises the semaphore regardless of the semaphore state. If a process calls the \CSPM{down} method when the semaphore is raised, the semaphore becomes lowered. However, if the semaphore is unraised, the process waits until another process calls \CSPM{up} and proceeds to put down the semaphore. Depending on the initial state of the semaphore, a binary semaphore can be further categorized as a mutex semaphore or a signalling semaphore.

Modelling a semaphore is straightforward in CSP. Figure \ref{semaphore.csp} is the CSP semaphore module. A process may call \CSPM{up} function or \CSPM{down} function via channel \CSPM{upChan} or channel \CSPM{downChan} respectively. The semaphore is modelled by a process implemented by two mutually recursive functions \CSPM{Semaphore(True)} and \CSPM{Semaphore(False)}. The semaphore process representing an unraised state accepts a \CSPM{upChan} event by any process and proceeds to the raised process. The semaphore process representing a raised state can either accept a \CSPM{upChan} event and recurse to the raised process, or accept a \CSPM{downChan} event and proceed to the unraised process.

Like the shared variable in the earlier subsection, the semaphore is encapsulated in a CSP module. To create a semaphore, one needs to supply two arguments. \CSPM{TypeThreadID} is the set of identities of processes that use this semaphore. \CSPM{initialState} is a boolean value indicating the starting state of the semaphore. If \CSPM{initialState} is true, the semaphore is raised initially. Otherwise, the semaphore is lowered. 
\begin{cspfloat}{semaphore.csp}{The binary semaphore module in CSP}
module ModuleSemaphore(TypeThreadID, initialState)
  --Raised
  Semaphore(True) = downChan?id -> Semaphore(False)
                   [] upChan?id -> Semaphore(True)
  --Unraised
  Semaphore(False)= upChan?id   -> Semaphore(True)
  
  chanset = {|upChan, downChan|}
exports
  --runWith::(Bool,Proc) -> Proc
  runWith(hide,P) = (Semaphore(initialState) [| chanset |] P) \ 
                     (if hide then chanset else {})
  channel upChan, downChan: TypeThreadID
endmodule
\end{cspfloat}

\subsection{Monitor}
\subsubsection{JVM Monitor}
A Monitor is another powerful concurrent primitive. This thesis will also use a simplified monitor from \cite{CPinJava}. JVM Monitor provides two key features, mutual exclusion and waiting. 

Monitors can be used to prevent race conditions. At any time, only one process can run code inside a synchronized block that belongs to one monitor. The function \CSPM{op1} in Figure \ref{monitor.scala.example} uses synchronized block to prevent race condition on variable $a$. 

Inside a \CSPM{synchronized} block, the process can also perform \CSPM{wait}, \CSPM{notify}, and \CSPM{notifyAll}. When a process inside the synchronized block calls \CSPM{wait}, the process suspends and waits for notification from other processes. Since a waiting process may be spurious waked up, so a \CSPM{wait} call is used with a while loop and a condition. In the MoniorExample of Figure \ref{monitor.scala.example}, \CSPM{op2} waits until there is 10 \CSPM{op1} calls. In \CSPM{op1}, a process calls \CSPM{notifyAll} after incrementing the shared variale \CSPM{a}. When there aren't 10 \CSPM{op1} calls, process waiting in \CSPM{op2} first wakes, finds the condition $a<10$ true, and returns to sleep. 


\begin{scalafloat}{monitor.scala.example}{A simple Scala class that uses a monitor internally}
class MonitorExample {
  private var a = 0;

  def op1():Unit = synchronized{ 
    a=(a+1)%20; 
    notifyAll()
  }
  def op2():Unit = synchronized{ 
    while(a<10) wait();
  }
}
\end{scalafloat}
  
\subsubsection{Monitor Module}
The monitor process has two states and behaves differently in two states, captured by two processes in Figure \ref{monitor.csp.1}.

When there is no running process, the behaviour of the monitor is captured by the CSP process \CSPM{inactive}, with parameter \CSPM{waiting} being the set of waiting processes. The monitor can allow a process to run synchronized code with a \CSPM{waitEnter} event. Or, the monitor can spuriously wake a process with a \CSPM{SpuriousWake} event, and the spuriously waken process behaves like a normally waken process.

When there is a running process, the behaviour of the monitor is captured by the CSP process \CSPM{active}, with parameter \CSPM{cur} being the identity of the process running \CSPM{synchronized} block, and \CSPM{waiting} being the set of the waiting process. The monitor process should respond to method calls from the running process \CSPM{cur}, and the monitor should not allow another process to obtain the monitor lock. In \CSPM{active} state, the monitor can also spuriously wake a waiting process. 

On the client process side, most functions are implemented by simply synchronizing with the monitor on an event. For example, before entering the \CSPM{synchronized} block, the process sends a \CSPM{WaitEnter} event. The only exception is the \CSPM{wait} function, as after being notified, the process needs to resume execution. The process first sends a \CSPM{wait} event to tell the monitor that it is waiting and release the monitor lock. The monitor then receives a \CSPM{waitNotify} or \CSPM{spuiousWake} event, for being notified. Then the process reobtains the monitor lock with a \CSPM{waitEnter} event. 

The monitor module also provides a few useful macros. The \CSPM{synchronized} function wraps a CSP code to run under the protection of the monitor. The \CSPM{whilewait} function implements the common Scala pattern `while(cond) wait()`. The implementation uses a functional replacement for \CSPM{while} statement in imperative programming languages. The \CSPM{cond} parameter is a CSP function of type `(Proc, Proc) -> Proc`. The return process of \CSPM{cond} first performs some events to check the condition of the while statement. If the condition is true, the return process continues to run the process in the first parameter, or the return process runs the process in the second parameter.

With these process side functions and macros, the Scala MonitorExample class in Figure \ref{monitor.scala.example} can be converted into the CSP code in Figure \ref{monitor.csp.example}.

\begin{cspfloat}{monitor.csp.example}{The CSP implementation of MonitorExample in Figure \ref{monitor.scala.example}}
instance VarA = ModuleVariable({0..20},0)
instance Monitor = ModuleMonitor(TypeThreadID, False)

op1(me)=synchronized(me,
  --a=(a+1)%20; 
  VarA::getValue?x -> VarA::setValue!((x+1)%20) ->
  --notifyAll();
  Monitor::notifyAll(me)
)

op2(me)=synchronized(me,
  --while(a<10) wait()
  Monitor::whileWait(me, \ktrue,kfalse @
    VarA::getValue?x -> if x<10 then ktrue else kfalse
  )
)
\end{cspfloat}
  

There are two design choices worth mentioning in the implementation of the monitor. 

First, note that both \CSPM{WaitNotify} and \CSPM{SpuriousWake} events come from the monitor process instead of directly synchronizing with the currently running process. When a process calls \CSPM{notify} or \CSPM{notifyAll}, it needs to synchronize with the monitor process. This is because the running process does not know how many processes are waiting. If the monitor is implemented the other way, the notifying process will block if there is no waiting process. Similarly, a process calling \CSPM{notifyAll} does not know how many processes it should wake up. 

Secondly, a monitor can introduce divergence by repetitively spuriously waking up a waiting process, whose condition keeps unsatisfied and never changes. This is an unwanted behaviour in failure testing. So the monitor module has an extra parameter \CSPM{disableSpurious} to disable spurious wakeups. 


\begin{cspfloat}{monitor.csp.1}{The CSP Monitor Module - Part 1 - the monitor process}
module ModuleMonitor(TypeThreadID)
  channel Notify, NotifyAll, Exit, Wait, 
          WaitNotify, WaitEnter, SpuriousWake: TypeThreadID

  chanset = {| Notify, NotifyAll, Exit, Wait, WaitNotify, WaitEnter, SpuriousWake|}

  --A list of event for every event e in s
  repeat(ch, s) = if s=={} then SKIP else ch?a:s -> repeat(ch, diff(s, {a}))

  --cur is current active running thread
  --waiting is a set of threads waiting to be notified
  active(cur, waiting) =
    --current running thread notify
    Notify.cur -> (
      --do nothing if no thread is waiting
      if waiting=={} then active(cur, {})
      --wakeup a process
      else WaitNotify?a:waiting -> 
           active(cur, diff(waiting, {a}))
    ) [] --current running thread notifyAll
    NotifyAll.cur -> (
      repeat(WaitNotify, waiting);
      active(cur, {})
    ) [] --current running thread exit
    Exit.cur -> (
      inactive(waiting)
    ) [] --current running thread wait
    Wait.cur -> (
      inactive(union(waiting,{cur}))
    ) [] --spurious wakeup
    waiting!={} & SpuriousWake?a:waiting -> (
      active(cur, diff(waiting, {a}))
    )

  --when no active thread is running
  inactive(waiting) = 
    --pick a thread that is ready to enter
    WaitEnter?a -> (
      active(a, waiting)
    ) []
    --spurious wakeup
    waiting!={} & SpuriousWake?a:waiting -> (
      inactive(diff(waiting, {a}))
    )
\end{cspfloat}

\begin{cspfloat}{monitor.csp.2}{The CSP Monitor Module - Part 2 - client process side functions}
exports
  --Given a process that uses the monitor
  --Return the process synchronized with the monitor server process
  --If hide is true, monitor channels are hidden
  runWith(hideSpurious, hideInternal, P) = 
    let hideset0 = if hideInternal then chanset else {} within
    let hideset1 = if hideSpurious then hideset0 
                   else diff(hideset0,{|SpuriousWake|}) within
    (inactive({}) [|chanset|] P) \ hideset1
  
  --java-like synchronized function
  synchronized(me, P)= WaitEnter.me -> P; Exit.me -> SKIP

  enter(me) = WaitEnter.me -> SKIP

  exit(me) = Exit.me -> SKIP

  --notify()
  notify(me) = Notify.me -> SKIP

  --notifyAll()
  notifyAll(me) = NotifyAll.me -> SKIP

  --wait()
  wait(me) =
    Wait.me -> (
      (WaitNotify.me -> WaitEnter.me -> SKIP)
    [](SpuriousWake.me -> WaitEnter.me -> SKIP)
    )
  
  whileWait(me,cond) = while(cond)(wait(me);SKIP)
endmodule
\end{cspfloat}

\newpage
\section{MenWomen}
The MenWomen object is a classical problem from the concurrent programming course. In the problem, some processes need to pair off and share identities between the paired processes. Figure \ref{menwomen.scala.interface} is the interface of the MenWomen object. A process can call \CSPM{manSync} from the object to pair with a process calling \CSPM{womanSync}. Also a process can call \CSPM{womanSync} from the object to pair with another process calling \CSPM{manSync}. For simplicity, if a process is calling \CSPM{manSync}, we shall call it a man process. Similarly, a process calling \CSPM{manSync} is called a woman process.

\begin{scalafloat}{menwomen.scala.interface}{Scala Interface of the MenWomen object}
trait MenWomenT{
  def manSync(me: Int): Int
  def womanSync(me: Int): Int
}
\end{scalafloat}

\subsection{Implementation}
One way to implement the MenWomen object is to use a monitor and a shared variable indicating the stage of synchronization. Figure \ref{menwomen.scala.correct} is a Scala implementation of the MenWomen object with monitor.
\begin{itemize}
  \item A man process enters the synchronization and waits until the current stage is $0$. Then in stage $0$, the man process sets the global variable \CSPM{him} inside the \CSPM{MenWomen} object to its identity. Then the man process notifies all processes so that a waiting woman process can continue. Finally, the man process waits for stage 2.
  \item A women process enters the synchronization and waits until the current stage is $1$. The woman process sets the global variable \CSPM{her} to its identity and returns the value of the global variable \CSPM{him}.
  \item In stage $2$, the waiting man process in stage $0$ is wakened up by the woman process in stage $1$. The man process notifies all waiting processes and returns the value of \CSPM{her}.
\end{itemize}

The code snippet in Figure \ref{menwomen.scala.correct} is a Scala implementation of the MenWomen process using a monitor by Gavin Lowe. With the shared variable and monitor module, the Scala code is further translated to a CSP code in Figure \ref{menwomen.csp.correct}. With the convention described in the introduction section, every function call begins with a Call event containing all parameters. And every function call ends with a Return event containing the return value.

\begin{scalafloat}{menwomen.scala.correct}{A correct MenWomen object implementation in Scala}
class MenWomen extends MenWomenT{
  private var stage = 0
  private var him = -1
  private var her = -1

  def manSync(me: Int): Int = synchronized{
    while(stage != 0) wait()         
    him = me; stage = 1; notifyAll() 
    while(stage != 2) wait()
    stage = 0; notifyAll(); her
  }

  def womanSync(me: Int): Int = synchronized{
    while(stage != 1) wait()
    her = me; stage = 2; notifyAll();
  }
}
\end{scalafloat}

\begin{cspfloat}{menwomen.csp.correct}{Translated CSP code for the correct MenWomen object immplementation}
instance VarStage = ModuleVariable({0,1,2},0) 
instance VarHim = ModuleUninitVariable(TypeThreadID)
instance VarHer = ModuleUninitVariable(TypeThreadID)
instance Monitor = ModuleMonitor(TypeThreadID)
manSync(me) = 
  Call!me!ManSync ->
  Monitor::enter(me);
    Monitor::whileWait(me, \ktrue,kfalse @
      VarStage::getValue?x ->
      if x!=0 then ktrue else kfalse
    );
    VarHim::setValue!me ->
    VarStage::setValue!1 ->
    Monitor::notifyAll(me);
    Monitor::whileWait(me, \ktrue,kfalse @
      VarStage::getValue?x ->
      if x!=2 then ktrue else kfalse
    );
    VarStage::setValue!0 ->
    Monitor::notifyAll(me);
    VarHer::getValue?ans ->(
  Monitor::exit(me);
  Return!me!ManSync!ans->
  SKIP
  )
womanSync(me)=
  Call!me!WomanSync ->
  Monitor::enter(me);
    Monitor::whileWait(me, \ktrue,kfalse @
      VarStage::getValue?x ->
      if x!=1 then ktrue else kfalse
    );
    VarHer::setValue!me ->
    VarStage::setValue!2 ->
    Monitor::notifyAll(me);
    VarHim::getValue?ans ->(
  Monitor::exit(me);
  Return!me!WomanSync!ans->
  SKIP
  )
\end{cspfloat}


\subsection{Linearization Test}
Recall that in the testing system, each process can call any function provided by the concurrent datatype or choose to terminate. In defining processes in the testing system, a helper function is used. \CSPM{chaosP(P)} runs the process \CSPM{P} forever or terminates after running a finite number of \CSPM{P}. The processes in the testing system simply use \CSPM{chaosP} with a process that non deterministically chooses to perform \CSPM{manSync} or \CSPM{womanSync} with their identities. 

\begin{cspinline}{helper.chaosP}{Definition of helper function chaosP and processes in the testing system}
chaosP(P) = (P;chaosP(P)) |~| SKIP
Thread(me)=chaosP(manSync(me) |~| womanSync(me))
\end{cspinline}
  
All processes in the testing system interleave with other processes and synchronize with the processes of shared variables and the process of the monitor. Since the testing system should only include \CSPM{Call} and \CSPM{Return} events, all other events are hidden using the first two boolean flags in \CSPM{runWith} defined in earlier sections. 

\begin{cspinline}{menwomen.csp.testsystem}{Definition of CSP processes in the testing system}
System(All)=runWith(True,True,||| me:All @ Thread(me))
\end{cspinline}

\CSPM{Sync} events represent the synchronization between a man process and a woman process, which is used internally in the testing specification. The CSP code below is the definition and specification of \CSPM{Sync} channel. 

\begin{cspinline}{menwomen.csp.sync}{Definition of Sync channel}
  channel Sync: TypeThreadID.TypeThreadID.TypeThreadID.TypeThreadID
  Spec(All) = Sync?man:All?woman:diff(All,{man})!woman!man -> Spec(All)
\end{cspinline}
  
A \CSPM{Sync} event takes four parameters, the identity of the man process, the return value of the man process, the identity of the woman process, the return value of the woman process. For each synchronization, the spec proecess ensure two properties. First, synchronization occurs between two different processes. Second, the return value of each participating process is the identity of the other participating process. 


A linearizer ensures two properties. The return value of a function call comes from the synchronization. And the synchronization point occurs sometime during the function call. The \CSPM{Linearizer} function for \CSPM{MenWomen} achieves this by two branches of CSP processes, each representing a method in the object. Each branch starts with a \CSPM{Call} event, then a \CSPM{Sync} event with its identity, and finally a \CSPM{Return} event which computes from the \CSPM{Sync} event. In addition to the two branches, the linearizer process should be able to \CSPM{STOP} to match the behaviour in the testing system.

Finally, \CSPM{Linearizer(All)} composites the \CSPM{Sync} specification with the linearizer processes so that the \CSPM{Sync} events are valid according to the \CSPM{Sync} specification and \CSPM{Sync} events are agreed by both participating process. The latter property is achieved using replicated generalized parallel. By the semantic of the replicated generalized parallel, when a process wants to perform an event, the process must synchronize all other processes which can perform this event. Figure \ref{menwomen.lin.simple} visualizes a trace generated by \CSPM{Linearizers({T1,T2})} by the FDR debugging window. When a linearizer performs \CSPM{Call} and \CSPM{Return}, the linearizer does not synchronize with any process. When \CSPM{linearizer(T1)} performs \CSPM{Sync.T1.T2.T2.T1}, \CSPM{linearizer(T2)} and \CSPM{Spec} must also perform the \CSPM{Sync} event.
\svginline{menwomen.lin.simple}{FDR Visualization of traces of a man process and a woman process synchronizing}

All above properties suffice to show that \CSPM{Linearizers(All)} generates all traces that correspond to a valid history and that \CSPM{Linearizers} is a valid specification process for the testing system. Informally, for any valid history, a linearizability test can find a set of synchronization points, which corresponds to a trace of the specification for \CSPM{Sync} events. Furthermore, the valid history can be obtained by adding respective call and return events around synchronization points. 

\begin{cspfloat}{menwomen.csp.lin}{Definition of linearizer process in CSP}
Lin(All,me)= (
  Call!me!ManSync->
  Sync!me?mereturn?other:diff(All,{me})?otherreturn ->
  Return!me!ManSync!mereturn ->
  Lin(All,me)
)|~|(
  Call!me!WomanSync ->
  Sync?other:diff(All,{me})?otherreturn!me?mereturn ->
  Return!me!WomanSync!mereturn ->
  Lin(All,me)
)|~|STOP
LinEvents(All,me)=union({
  ev | ev<-{|Sync|},
  let Sync.t1.a.t2.b=ev within
    countList(me,<t1,t2>)==1 and member(t1,All) and member(t2,All)
},{|Call.me,Return.me|})
  
Linearizers(All)=((|| me: All @ [LinEvents(All,me)] Lin(All,me)) [|{|Sync|}|] Spec(All)) 
                  \{|Sync|}
\end{cspfloat}
  
Finally, we perform the test using trace refinement for safety property and failure refinement for liveness. As expected, the correct implementation passes all tests. 
\begin{cspinline}{menwomen.csp.test}{Part of liveness and safetyness test in CSP for MenWomen object}
System2=System({T1,T2})
Spec2Thread=Linearizers({T1,T2})
assert Spec2Thread [T= System2
assert Spec2Thread [F= System2
\end{cspinline}


\subsection{A faulty version}
We shall examine another MenWomen implementation in Figure \ref{menwomen.scala.faulty}. One key difference in this faulty MenWomen object is that it uses \CSPM{Option} data in the shared variables to store the identity of the process calling \CSPM{manSync} and the process calling \CSPM{womanSync}. 

\begin{scalafloat}{menwomen.scala.faulty}{A Faulty Scala implementation of MenWomen object}
class FaultyMenWomen extends MenWomenT{
  private var him: Option[Int] = None
  private var her: Option[Int] = None

  def manSync(me: Int): Int = synchronized{
    while(him.nonEmpty) wait()
    him = Some(me); notifyAll()
    while(her.isEmpty) wait()   
    val Some(res) = her
    her = None; notifyAll()
    res
  }

  def womanSync(me: Int): Int = synchronized{
    while(her.nonEmpty) wait()
    her = Some(me); notifyAll()
    while(him.isEmpty) wait()  
    val Some(res) = him
    him = None; notifyAll()
    res
  }
}
\end{scalafloat}

The safeness property test shows that this implementation handles scheduling carelessly. This implementation fails the test \CSPM{Spec2Thread [T= System2}, and FDR provides a trace that violates the safeness specification, shown in Figure \ref{menwomen.faulty.trace}. FDR further allows the user to expand the hidden $\tau$ events in the testing system, which are normally processes' interactions with shared variables and the monitor. By understanding the expanded trace in CSP, we can find a equivalent way to trigger the bug in Scala.

\svginlinescaled{menwomen.faulty.trace}{0.95}{Trace}

\begin{itemize}
  \item A process \CSPM{T1} calls \CSPM{manSync}. On first line, since the shared variable \CSPM{him} is initially \CSPM{None}, \CSPM{T1} skips the \CSPM{wait}, set \CSPM{him} to \CSPM{Some(T1)} and waits for a process calling \CSPM{womanSync}.
  \item A process \CSPM{T2} calls \CSPM{womanSync} and returns \CSPM{T1}. At this stage, there is no waiting process waiting to run \CSPM{womanSync} and the shared variable is not \CSPM{None}. So \CSPM{T2} does not wait at any point, notifies all waiting process, and returns.
  \item Before \CSPM{T1} reenters the \CSPM{synchronized} block, process \CSPM{T2} calls \CSPM{womanSync} again. \CSPM{him} has not been reset by \CSPM{T1} yet. So \CSPM{T2} pairs with \CSPM{T1} again, which should not be allowed. 
\end{itemize}

\newpage
\section{ABC}
With an ABC object, three processes can exchange data with each other two processes. More specifically, one process calling \CSPM{aSync}, one process calling \CSPM{bSync}, and one process calling \CSPM{cSync} synchronizes. Then each of the three processes returns with the arguments of two other processes. For simplicity, we shall call a process calling \CSPM{syncA} as an A-process, a process calling \CSPM{syncB} as a B-process, and a process calling \CSPM{syncC} as a C-process. 

One of the challenges to check an ABC object is the huge number of states in the CSP model. In this section, we shall see how the linearizer process can be optimized and the efficiency of the explicit linearization point test.

\subsection{Implementation}
Figure \ref{abc.scala.correct} is a Scala implementation of a ABC object with semaphore. In each round of synchronization,
\begin{itemize}
    \item Initially semaphore \CSPM{aClear} is raised. An A-process acquires semaphore \CSPM{aClear}, sets the shared variable \CSPM{a} to its parameter, raises semaphore \CSPM{bClear} and waits to acquire semaphore \CSPM{aSignal}. A B-process and a C-process behaves similarly in turn, except they use different semaphores and shared variables. 
    \item After a C-process raises semaphore \CSPM{aSignal}, the A-process is able to continue. The A-process reads the shared variable \CSPM{b} and \CSPM{c}, raises the semaphore \CSPM{bSignal}, and returns \CSPM{b} and \CSPM{c}. Likewise, B and C also take the value of two other shared variable and raise respective semaphores in turn.
\end{itemize}

Using the shared variable and semaphore module, it is easy to translate the Scala implementation to a CSP implementation.

\begin{scalafloat}{abc.scala.correct}{A semaphore-based Scala implementation of the ABC object}
class ABC[A,B,C] extends ABCT[A,B,C]{
  // The identities of the current (or previous) threads.
  private var a: A = _
  private var b: B = _
  private var c: C = _

  // Semaphores to signal that threads can write their identities.
  private val aClear = MutexSemaphore()
  private val bClear, cClear = SignallingSemaphore()

  // Semaphores to signal that threads can collect their results. 
  private val aSignal, bSignal, cSignal = SignallingSemaphore()

  def syncA(me: A) = {
    aClear.down         // (A1)
    a = me; bClear.up   // signal to b at (B1)
    aSignal.down        // (A2)
    val result = (b,c)
    bSignal.up          // signal to b at (B2)
    result
  }

  def syncB(me: B) = {
    bClear.down         // (B1)
    b = me; cClear.up   // signal to C at (C1)
    bSignal.down        // (B2)
    val result = (a,c)
    cSignal.up          // signal to c at (C2)
    result
  }

  def syncC(me: C) = {
    cClear.down         // (C1)
    c = me; aSignal.up  // signal to A at (A2)
    cSignal.down        // (C2)
    val result = (a,b)
    aClear.up           // signal to an A on the next round at (A1)
    result
  }
}      
\end{scalafloat}

\begin{cspfloat}{abc.csp.correct}{Translated CSP Code for the correct ABC implementation}
instance VarA = ModuleUninitVariable(TypeData) 
instance VarB = ModuleUninitVariable(TypeData)
instance VarC = ModuleUninitVariable(TypeData)

instance aClear = ModuleMutexSemaphore(TypeThreadID)
instance bClear = ModuleSignallingSemaphore(TypeThreadID)
instance cClear = ModuleSignallingSemaphore(TypeThreadID)
instance aSignal = ModuleSignallingSemaphore(TypeThreadID)
instance bSignal = ModuleSignallingSemaphore(TypeThreadID)
instance cSignal = ModuleSignallingSemaphore(TypeThreadID)

runWith(hide,p)=
  VarA::runWith(hide,
  VarB::runWith(hide,
  VarC::runWith(hide,
  aClear::runWith(hide,
  bClear::runWith(hide,
  cClear::runWith(hide,
  aSignal::runWith(hide,
  bSignal::runWith(hide,
  cSignal::runWith(hide,
    p
  )))))))))

SyncA(me,avalue) =
  Call!me!ASync!avalue ->
  --aClear.down
  aClear::downChan!me ->
  --a = me
  VarA::setValue!avalue ->
  --bClear.up
  bClear::upChan!me ->
  --aSignal.down
  aSignal::downChan!me ->
  --(b,c)
  VarB::getValue?b ->
  VarC::getValue?c ->
  --bSignal.up
  bSignal::upChan!me ->
  --result ->
  Return!me!ASync!(b.c) ->
  SKIP

...
\end{cspfloat}

\subsection{Testing}
Similar for the MenWomen object, a testing system is defined through any number of working processes and a specification is built from a \CSPM{Sync} channel, linearizer processes, and a synchronization alphabet set. 

One key difference of the \CSPM{ABC} object is that processes can call with any argument from the set \CSPM{TypeData}, whereas in \CSPM{MenWomen} object, processes can only call with their identity. Inside \CSPM{chaosP}, the processes also choose an argument with General Non-Deterministic Choice. 

\begin{cspinline}{abc.csp.worker}{Definition of processes in the testing system.}
Thread(me)=chaosP( |~| x:TypeData @ (
    SyncA(me,x) 
  |~| SyncB(me,x) 
  |~| SyncC(me,x)
))
\end{cspinline}

The testing specification uses the same component, the \CSPM{Sync} channel, linearizer processes, and linEventns. The definition of \CSPM{Sync} channel is shown in Figure \ref{abc.csp.sync}. The event $Sync.t_1.a.b.c.t_2.d.e.f.t_3.g.h.i$ represents the synchronizations between three threads, $t_1,t_2,t_3$. Process $t_1$ calls \CSPM{aSync} with $a$ and returns $(b,c)$. The second process $t_2$ calls \CSPM{bSync} with $d$ and returns $(e,f)$. And the last process $t_3$ calls \CSPM{cSync} with $g$ and returns $(h,i)$. The Sync specification process, shown in the same figure, checks that in each \CSPM{Sync} events, the return value of each process is the pair of arguments of the two other function call. 

Figure \ref{abc.csp.lin} is the definition of a linearizer process, written a similar format with the MenWomen object.

\begin{cspfloat}{abc.csp.sync}{Definition of Sync channel and specification of Sync event}
--thread identity calling ASync. ASync parameter a. ASync return pair (b,c)
--thread identity calling BSync. BSync parameter b. BSync return pair (a,c)
--thread identity calling CSync. CSync parameter c. CSync return pair (a,b)
channel Sync: TypeThreadID.TypeData.TypeData.TypeData.
              TypeThreadID.TypeData.TypeData.TypeData.
              TypeThreadID.TypeData.TypeData.TypeData

Spec(All) = 
  Sync?t1:All?a?b?c
      ?t2:diff(All,{t1})!b!a!c
      ?t3:diff(All,{t1,t2})!c!a!b -> 
  Spec(All)
\end{cspfloat}

\begin{cspfloat}{abc.csp.lin}{Definition of linearizer process}
--Linearizer for a process
Lin(All,me)=(
  --me synchronizes as thread A
  Call!me!ASync?a ->
  Sync!me!a?b?c?t2:diff(All,{me})?t2b?t2a?t2c?t3:diff(All,{me,t2})?t3c?t3a?t3b ->
  Return!me!ASync!b!c ->
  Lin(All,me)
) |~| (
  --me synchronizes as thread B
  Call!me!BSync?b ->
  Sync?t2:diff(All,{me})?t2b?t2a?t2c!me!b?a?c?t3:diff(All,{me,t2})?t3c?t3a?t3b ->
  Return!me!BSync!a!c ->
  Lin(All,me)
) |~| (
  --me synchronizes as thread C
  Call!me!CSync?c ->
  Sync?t2:diff(All,{me})?t2b?t2a?t2c?t3:diff(All,{me,t2})?t3a?t3b!me!c?a?b ->
  Return!me!CSync!a!b ->
  Lin(All,me)
)
\end{cspfloat}

\begin{cspinline}{abc.csp.test}{Part of test for ABC object. This tests a system with three processes.}
System3=System({T1,T2,T3})
Spec3Thread=Linearizers({T1,T2,T3})

assert Spec3Thread [T= System3
assert Spec3Thread [F= System3
\end{cspinline}
\subsubsection{Speeding up model compilation}
Consider the specification process with three processes. Let $M$ be the size of the set of all possible arguments. Conside r the trace in Figure \ref{abc.timeline.lin}, where process \CSPM{T1} calls \CSPM{aSync} with \CSPM{A}, \CSPM{T2} calls \CSPM{bSync} with \CSPM{B}, \CSPM{T3} calls \CSPM{cSync} with \CSPM{C}. Then they synchronization.

\svginlinescaled{abc.timeline.lin}{0.95}{The set of possible Sync event for each CSP process}

The last transition in the diagram is the \CSPM{Sync} event between three processes. Above the edge is the set of possible \CSPM{Sync} event that every process accepts. Each linearizer accepts $3^2*M^8$ possible \CSPM{Sync} event. The combined linearizer accepts $M^6$ sync event. However, according to the sync specification, only one \CSPM{Sync} event is valid. 
    
With the above analysis, it is tempting to reduce the redundancy in \CSPM{Sync} event. Optimize the linearizer process by using the information from the specification process. Instead of choosing all possible remaining arguments, the individual linearizer could choose correct arguments according to the specification process. Figure \ref{abc.csp.simple1} includes part of the simplified code. This change does not reduce the number of transitions in the resulting specification, but it helps FDR build the process faster.

With this optimization, the testing for less than 5 processes finishes quickly.

\begin{cspfloat}{abc.csp.simple1}{Simplified definition of Sync channel and part of simplified linearizer}
  --A modified version of lin2
  --slow
  channel Sync: TypeThreadID.TypeThreadID.TypeThreadID.TypeData.TypeData.TypeData
  
  --Linearizer for a process
  Lin(All,me)= (
        --me synchronizes as thread A
        Call!me!ASync?a ->
        Sync!me?t2:diff(All,{me})?t3:diff(All,{me,t2})!a?b?c ->
        Return!me!ASync!b!c ->
        Lin(All,me)
      ) |~| (
        --me synchronizes as thread B
        Call!me!BSync?b ->
        Sync?t2:diff(All,{me})!me?t3:diff(All,{me,t2})?a!b?c ->
        Return!me!BSync!a!c ->
        Lin(All,me)
      ) |~| (
        --me synchronizes as thread C
        Call!me!CSync?c ->
        Sync?t2:diff(All,{me})?t3:diff(All,{me,t2}) !me?a?b!c ->
        Return!me!CSync!a!b ->
        Lin(All,me)
      ) |~| STOP
  LinEvents(All,me)=union({
    e | e <- {|Sync|},
    let Sync.t1.t2.t3.a.b.c=e within
      countList(me,<t1,t2,t3>)==1 and member(t1,All) and member(t2,All) and member(t3,All)
  },{|Call.me,Return.me|})
  Linearizers(All)= (|| me: All @ [LinEvents(All,me)]  Lin(All,me)) \ {|Sync|}
\end{cspfloat}

\subsection{Faulty version}
Recall that in Java and Scala, raising a semaphore immediately allows another thread waiting to acquire the semaphore to continue. So it is essential to take a copy of the two other arguments before raising the semaphore.

On the other hand, what if the implementation of \CSPM{syncA} does not take a copy of the argument? It turns out that the faulty \CSPM{ABC} object passes tests for three processes but fails the linearisation test with at least four threads.


\subsubsection{Explanation of the error case}
For the test \CSPM{Spec4Thread [T= System4}, FDR displays a trace of the testing system that violates the specification. From the trace, it seems that process \CSPM{T1} synchronizes with \CSPM{T2} and \CSPM{T3} in the first round, and should return \CSPM{(B,C)}, but \CSPM{(E,F)}, the argument in the second round is returned. Expanding the $\tau$ event and translating CSP traces into program traces makes it possible to see what goes wrong in the faulty version when there are four threads.

\svginlinescaled{abc.faulty.trace}{0.9}{Trace that violates the specification}

\begin{itemize}
  \item In the first round of synchronization, process $T_A$, $T_B$, $T_C$ call \CSPM{aSync}, \CSPM{bSync} or \CSPM{cSync} respectively, and put down its argument in turn.
  \item Process $T_A$ raises \CSPM{bSignal}. Before $T_A$ exits, the other two processes $T_B$, $T_C$ returns. Now $T_A$ should return argument of $T_B$ and $T_C$.
  \item Another round of synchronization starts. Thread $T_D$, $T_B$, $T_C$ call \CSPM{aSync}, \CSPM{bSync} or \CSPM{cSync} respectively, and overwites the shared variable \CSPM{a,b,c} in turn.
  \item Now $T_A$ returns with $(b,c)$ from the second round, which may not be the argument of \CSPM{bSync} and \CSPM{cSync} in the first round.
\end{itemize}

\subsection{Explicit linearization point test}
In this section, we describe another fast testing technique. In explicit synchronization test, one first understands the implementation of the object and finds synchronization point, where synchronization occurs between processes. Then based on the observation, one writes the specification for the these synchronization point. Finally, one checks that a testing system with only LP events visible refines the specification for LP.

From the source code of the ABC object, synchronizations occur in six places. The first three synchronizations occur when processes set the respective shared variables before raising semaphores. The other synchronizations occur when the processes read the shared variables after lowering semaphores. For every synchronization, the respective CSP lines are replaced with a \CSPM{LP} event and the shared variable module is adapted to listen on the \CSPM{LP} event. Figure \ref{abc.explicit.async} is the definition of LP events and the implementation of \CSPM{SyncA}. 
\begin{cspfloat}{abc.explicit.async}{aSync function in explicit linearization point testing}
SyncA(me,avalue) =
  --aClear.down
  aClear::downChan!me ->
  --a = me
  LP1!me!avalue ->
  --bClear.up
  bClear::upChan!me ->
  --aSignal.down
  aSignal::downChan!me ->
  --(b,c)
  LP4!me!bvalue!cvalue ->
  --bSignal.up
  bSignal::upChan!me ->
  SKIP
\end{cspfloat}

The specification for the \CSPM{LP} events is simple. As described earlier in the section, the synchronization between process occurs in a fixed order. Initially only A-process is able to proceed to set the shared variable, then the B-process and the C-process can proceed in turn. In the second round the A-process, B-process, C-process reads the shared variables in turn. Figure \ref{abc.explicit.sync} is the specification process of \CSPM{LP} events. 

\begin{cspfloat}{abc.explicit.sync}{123}
spec(All) = 
  LP1?t1:All?a ->
  LP2?t2:diff(All,{t1})?b ->
  LP3?t3:diff(All,{t1,t2})?c ->
  LP4!t1!b!c ->
  LP5!t2!a!c ->
  LP6!t3!a!b ->
  spec(All)
\end{cspfloat}

Immediately we can see the specification process is much simpler than the process in linearization testing. But how fast is the explicit synchronization test? We use FDR to find the size of the state machine of the specification and testing system when three processes are involved. The sizes are organized in the table below. 

\begin{adjustbox}{width=\columnwidth,center}
\begin{tabular}{c c c c c}
  \hline
  & \multicolumn{2}{c}{Linearization test} & \multicolumn{2}{c}{Explicit Synchronization test} \\ \hline
  & Specification & Testing System & Specification & Testing System \\ \hline
  States      & $4*10^6$ & $4*10^5$ & $2*10^3$ & $1*10^5$\\ \hline
  Transitions & $1*10^7$ & $2*10^6$ & $1*10^4$ & $6*10^5$\\ \hline
\end{tabular}
\end{adjustbox}
\newline

As we can see from the table, the state machine of the specification process is much smaller in the explicit synchronization test. It is no surprise because the specification process in the explicit synchronization test is a simple recursive process. The state machine of the testing system is slightly smaller because the \CSPM{Call} and \CSPM{Return} events are removed in the explicit linearization test, and code execution is never interrupted by another process's return. 

However, the drawback of the explicit synchronization test is that it needs to be done on a per implementation basis. In the faulty implementation, the assumption on synchronization has changed. So the testing for correct implementation cannot be directly applied to the faulty implementation. 

\newpage
\section{Terminating Queue}
A terminating queue provides thread-safe enqueue and dequeue operations. Suppose a process dequeues when the queue is empty. The process blocks and waits for some process to enqueue. In addition, if all processes are dequeuing, no new element can be added to the queue and the whole system deadlocks. In this case, the queue terminates and returns \CSPM{None} for every process. Figure \ref{queue.scala.interface} is the interface of a terminating queue.

\begin{scalafloat}{queue.scala.interface}{Scala interface of terminating queue}
trait TerminatingQueueT[A]{ 
  def enqueue(x: A): Unit
  def dequeue: Option[A] 
}
\end{scalafloat}

A terminating queue is a stateful synchronization object, as earlier enqueue and dequeue operations affect later synchronizations. The timeline diagram below is invalid because the second \CSPM{dequeue} call should return 1 instead of 2. 

\svginline{queue.timeline.wrong}{A faulty timeline of termianting queue}

\subsection{Implementation}
The Scala implementation of the Terminating Queue wraps a Scala Queue with a monitor. Upon creation, the object is given \CSPM{numWorkers}, the number of processes using the terminating queue. In addition to an internal queue \CSPM{queue}, the terminating queue uses two more shared variables. The shared variable \CSPM{waiting} is the number of processes waiting to dequeue an element from the queue. The shared variable \CSPM{done} indicates if the queue has terminated. If the value of \CSPM{done} is true, then any further function call should do nothing.

Enqueue is a trivial operation. In the synchronized block, the process adds the element to the internal queue and notifies a process waiting to dequeue an element. Dequeuing is also trivial when the internal queue is not empty. The process simply performs \CSPM{dequeue} on the internal queue. When the queue is empty, if the value of \CSPM{waiting} is \CSPM{numWorkers-1}, then all processes are now waiting to dequeue, so the queue should terminate. The process notifies all waiting processes and returns \CSPM{None}. Otherwise, the process increments the counter \CSPM{waiting} and waits. The waiting process may be wakened for two cases. In the first case, a new element is added to the queue. The process decrements \CSPM{waiting} and returns the queue head as normal. In the second case, the process is wakened because the queue is terminating, and the process should return \CSPM{None}. 

\begin{scalafloat}{queue.scala.impl}{Scala implementation of terminating queue}
class TerminatingQueue[A](numWorkers: Int){
  private val queue = new Queue[A]
  private var waiting = 0
  private var done = false

  def enqueue(x: A) = synchronized{ 
    if(!done){
      queue.enqueue(x)
      if(waiting > 0) notify()
    }
  }

  def dequeue: Option[A] = synchronized{
    if(!done && queue.isEmpty){
      if(waiting == numWorkers-1){  // System should terminate
        done = true; notifyAll() 
      }  
      else{
        waiting += 1
        while(queue.isEmpty && !done) wait()
        waiting -= 1
      }
    }
    if(done) None else Some(queue.dequeue)
  }
}
\end{scalafloat}


A few workarounds are required to keep the state machine of the CSP model finite and analyzable for FDR. First, the range of variable \CSPM{waiting} is limited to integers from 0 to \CSPM{numWorkers} inclusive, instead of all $2^{32}$ possible values from a Scala integer. However, while building the state machine, FDR attempts to set the value of \CSPM{waiting} to \CSPM{-1} and \CSPM{numWorkers+1} and throws an error. Even though the value of \CSPM{waiting} will never be \CSPM{-1} or \CSPM{numWorkers+1} in the correct implementation, FDR is unable to derive such information while building the state machine for \CSPM{dequeue} when \CSPM{waiting} is 0 or \CSPM{numWorker}. As a workaround, we guard \CSPM{waiting} settings with an if statement in Figure \ref{queue.csp.correct}. Before setting the value of \CSPM{waiting}, the process checks if the new value is in range. If not, the process diverges. In the testing system, we check that system is divergence free to show that \CSPM{waiting} is always in range as expected.

Secondly, the Scala implementation uses a Scala Queue internally, which has unlimited capacity and cannot be modelled with finite states in CSP. To address this, we use a capacity-limited queue which behaves the same as the infinite queue when the queue is not full. However, if a process enqueues a new element when the internal queue is full, the process \CSPM{STOP} or \CSPM{DIV} according to what is required for testing. In Figure \ref{queue.csp.capqueue}, we implement the capacity-limited queue with many functions, The interface may be slightly overkilling for a capacity-limited queue, but it is necessary for a more powerful finite-state queue described in later subsections. 

\begin{cspfloat}{queue.csp.capqueue}{CSP Implementation of capacity-limited queue}
--Maximum number of element in the queue
NQueueCapacity=3
--Set of states of the capacity-limited queue
TypeQueue={q|i<-{0..NQueueCapacity},q<-ArrangementInList(i,TypeData)}
--Returns if the queue is empty
qEmpty(q)=q==<>
--Returns an empty queue
qNewQueue=<>
--Given a queue q, return a set of element that can be enqueued to queue q
qValidEnqueue(q)=if length(q)>=NQueueCapacity then {} else TypeData
--Given an element x, return a set of queues that accept an enqueue of x
qCanEnqueue(x)={q|q<-TypeQueue, length(q)<NQueueCapacity}
--Return the state of the queue after enqueueing x
qEnqueue(q,x)=q^<x>
--Return the set of all possible result and state pair after dequeueing
qDequeue(<>)={}
qDequeue(<qhead>^qtail)={(qhead,qtail)}
\end{cspfloat}

\begin{cspfloat}{queue.csp.correct}{CSP implementation of the termianting queue - Enqueue Part}
instance Monitor=ModuleMonitor(TypeThread, True)
instance VarQueue=ModuleVariable(TypeQueue,qNewQueue)
instance VarWaiting=ModuleVariable({0..5},0)
instance VarDone=ModuleVariable(Bool,false)

enqueue(NThread,me,x)=
  Call!me!(EnqueueCall.x) ->
  Monitor::synchronized(me,
    --if(!done)
    VarDone::getValue?done ->
    if (not done) then (
      --queue.enqueue(x), block until the queue is not full
      VarQueue::getValue?q ->
      if (not member(x,qValidEnqueue(q))) then QUEUE_ERROR_ACTION
      else (
        VarQueue::setValue!(qEnqueue(q,x)) ->
        --if(waiting > 0) notify()
        VarWaiting::getValue?waiting ->
        if(waiting>0) then Monitor::notify(me) else SKIP
    )) else SKIP
  );
  Return!me!(EnqueueReturn) ->
  SKIP






















  ⠀
\end{cspfloat}

\begin{cspfloat}{queue.csp.correct.2}{CSP implementation of the termianting queue - Dequeue Part}
dequeue(NThread,me)=
  Call!me!(DequeueCall) ->
  Monitor::enter(me);
  --if(!done && queue.isEmpty)
  VarDone::getValue?done ->
  VarQueue::getValue?q ->
  (if(not done and qEmpty(q)) then (
    --if(waiting == numWorkers-1)
    VarWaiting::getValue?x->
    if(x>=NThread) then DIV
    else if(x==NThread-1) then(
      --done=true
      VarDone::setValue!true->
      --notifyAll
      Monitor::notifyAll(me)
    )else(
      --waiting+=1
      --if(x==NThread) then div else
      VarWaiting::setValue!(x+1) ->
      --while(queue.isEmpty && !done) wait()
      Monitor::whileWait(me, \ktrue,kfalse @
        VarQueue::getValue?q ->
        VarDone::getValue?done ->
        if(qEmpty(q) and not done) then ktrue else kfalse
      );
      --waiting -= 1
      VarWaiting::getValue?y->
      if y==0 then DIV else 
      VarWaiting::setValue!(y-1)->
      SKIP
    )
  )else SKIP);
  --if(done) None else Some(queue.dequeue)
  VarDone::getValue?done ->
  if (done) then (
    Monitor::exit(me);
    Return!me!(DequeueReturnNone) ->
    --the thread should stop any work
    STOP
  ) else (
    VarQueue::getValue?q ->
    if qEmpty(q) then DIV else
    [] (ans, qtail): qDequeue(q) @
    VarQueue::setValue!qtail ->
    Monitor::exit(me);
    Return!me!(DequeueReturn.ans) ->
    SKIP
)

runWith(hideSpurious,hide,P)=
  VarQueue::runWith(hide,
  VarWaiting::runWith(hide,
  VarDone::runWith(hide,
  Monitor::runWith(hideSpurious,hide,
    P
  ))))
\end{cspfloat}

\subsection{Linearization Testing}
We use similar approaches to construct the testing system and the specification. For the terminating queue object, there are three synchronizations between a process and the object. When a process enqueues or successfully dequeues, it synchronizes with the object and acts on the internal queue. For \CSPM{enqueue} and \CSPM{dequeue}, the synchronization is represented by a Sync event with the identity of the process, an object representing the function call, and the return value. When the queue shuts down and a process returns \CSPM{None}, the process synchronizes with all other processes. In this case, the synchronization is represented by \CSPM{SyncShutdown}. 

Since a terminating queue is a stateful synchronization object, the specification of \CSPM{Sync} event is different from the earlier \CSPM{Sync} specification, in that the specification uses a parameter to keep the current queue. For both queues, the \CSPM{Sync} specification should ensure that elements are added and removed in a First-In-First-Out order, and all enqueue and dequeue operation are valid for the queue. \CSPM{Sync} specification does not check \CSPM{SyncShutdown} however. Figure \ref{queue.csp.sync} shows the definition of \CSPM{Sync} event and the specification. 

\begin{cspfloat}{queue.csp.sync}{Definition of Sync event and the specification}
channel Sync: TypeThread.TypeCallParam.TypeReturnParam
channel SyncShutDown
  
Spec(q)=
  (qValidEnqueue(q)!={} & [] x:qValidEnqueue(q) @ (
    Sync?t!(EnqueueCall.x)!EnqueueReturn -> 
    Spec(qEnqueue(q,x))
  ))[]
  (qDequeue(q)!={} & [](x,newq):qDequeue(q) @ (
    Sync?t!(DequeueCall)!(DequeueReturn.x) ->
    Spec(newq)
  ))[](
    qEmpty(q) & SyncShutDown -> STOP
  )
\end{cspfloat}

In addition to the safeness and liveness we usually test, we first check that the shared variable \CSPM{waiting} is actually in the range 0 to \CSPM{numWorkers}. We set spurious wakeup visible and invalid \CSPM{enqueue} to cause \CSPM{STOP}. If the testing system never diverges, it must be that a process always set a value from \CSPM{0} to \CSPM{numWorkers} for the variable \CSPM{waiting}.

For safeness and liveness testing, we use the normal setup, in which the spurious wakeup is invisible and the process diverges when it performs an invalid \CSPM{enqueue} operation.

\subsection{Faulty Implementation}
In this section, we use the linearization test to distinguish the correct implementation with three faulty implementations. In the first faulty implementation, \CSPM{enqueue} operation always adds \CSPM{A} to the internal queue regardless of the parameter of \CSPM{enqueue}. In the second faulty implementation, \CSPM{enqueue} method \CSPM{notify} does not wake up a process waiting to dequeue. The third implementation has a miss-by-one error. In \CSPM{dequeue}, A process checks \CSPM{waiting==numWorker} before incrementing \CSPM{waiting}. The result is shown in the table below.

\begin{tabular}{c c c c}
    \hline
    & Divergence Free & Trace Refinement & Failure Refinement \\ \hline
    Correct & Pass & Pass & Pass \\ \hline
    Faulty1 & Pass & Fail & Fail \\ \hline
    Faulty2 & Pass & Pass & Fail \\ \hline
    Faulty3 & Pass & Pass & Fail \\ \hline
\end{tabular}
\newline

With no surprise, the correct implementation passes all tests. The first faulty implementation fails all tests. The second faulty implementation fails only when spurious wakeups are disabled, as the missing \CSPM{notify} can be compensated by some "coincidental" spurious wakeup. It shows that when testing an object that internally uses a monitor, one should test it with spurious wake and without spurious wakeups from the monitor. The third faulty implementation shows a similar pattern. Because of the miss-by-one error, the last process will not terminate the queue. As a result, all processes refuse to return. However, as spurious wakeups can cause divergence, the failure model is unable to capture this error. 

\subsection{Test with another queue}
In this section, we apply the same tests with a different finite-state queue, which has infinite capacity but requires the element enqueued in A*BC* form. The queue is adapted from \cite{ABC}. If the test succeeds, the queue should not duplicate an element, reorder the enqueued element or miss an element with infinite data. 

When the A*BC* queue accepted some \CSPM{A} but no \CSPM{B}, the queue can enqueue an \CSPM{A} or a \CSPM{B}, but not a \CSPM{C}. When the queue accepted a \CSPM{B} or a \CSPM{C}, the queue can only enqueue a \CSPM{C} element. 

Dequeue operation can be non-deterministic in this queue. For example, the state \CSPM{QAsB0C} represents a queue with zero or more \CSPM{A} followed by a \CSPM{B}. A queue in state \CSPM{QAsB0C} accepts an dequeue of \CSPM{A} and an dequeue of \CSPM{B}. The state of the A*BC* queue is further split into empty states and non-empty states. For example, the state \CSPM{Q0C} is an empty state and rejects all dequeue operations. As shown in Figure \ref{queue.csp.abcqueue}, the implementation of the A*BC* queue is written in the same interface as the capacity-limited queue.

When the divergence free test, trace refinement test and the failure refinment test is applied on a system using the A*BC* queue, the test result shows a same pattern as earlier test on capacity limited queue. 
\begin{cspfloat}{queue.csp.abcqueue}{CSP Implementation of capacity-limited queue}
datatype TypeQueue= Q0A | QAAs | QAsB0C | QAsBCCs | Q0C  | QCCs
qEmpty(Q0A)=True
qEmpty(Q0C)=True
qEmpty(_)=False

qNewQueue=Q0A

qEnqueue(Q0A,    A)=QAAs
qEnqueue(Q0A,    B)=QAsB0C
qEnqueue(QAAs,   A)=QAAs
qEnqueue(QAAs,   B)=QAsB0C
qEnqueue(QAsB0C, C)=QAsB0C
qEnqueue(QAsBCCs,C)=QAsB0C
qEnqueue(Q0C,    C)=QCCs
qEnqueue(QCCs,   C)=QCCs

qValidEnqueue(Q0A)={A,B}
qValidEnqueue(QAAs)={A,B}
qValidEnqueue(_)={C}

qCanEnqueue(x)={q | q<-TypeQueue, member(x,qValidEnqueue(q))}

qDequeue(QAAs)=  {(A,Q0A),(A,QAAs)}
qDequeue(QAsB0C)={(A,QAsB0C),(B,Q0C)}
qDequeue(QAsBCCs)={(A,QAsBCCs),(B,QCCs)}
qDequeue(QCCs)={(C,Q0C),(C,QCCs)}
qDequeue(_)={}
\end{cspfloat}

\newpage
\section{Other objects}
There are several synchronization object we tested in the project, but testing on these object are not presented in this project due to the word limit. In this section we briefly describe their interface. Interested readers can refer to the appendix section for the CSP code of these objects.

Barrier is another synchronization object commonly used in concurrent programming. A \CSPM{sync} call returns only after all processes using the barrier calls \CSPM{sync}. 
\begin{scalafloat}{other.barrier}{}
trait BarrierT{
  def sync: Unit
}    
\end{scalafloat}

With the exchanger object, processes can exchange data with another process. Like the \CSPM{MenWomen} object, processes pair up and return the data of the other process.
\begin{scalafloat}{other.exchanger}{}
trait ExchangerT[A]{
  /** Exchange x with another thread. */
  def exchange(x: A): A
}
\end{scalafloat}

Filterchan is like a channel but a process can specify what data it wants to receive by providing a function as a parameter in \CSPM{receive}.
\begin{scalafloat}{other.filterchan}{}
trait FilterChanT[A]{
  /** Send x on the channel. */
  def send(x: A): Unit

  /** Receive a value that satisfies p. */
  def receive(p: A => Boolean): A
}
\end{scalafloat}

\newpage
\section{Conclusion}
The synchronization test technique can be used to test the correctness of a synchronization object given its interface and expected behaviour. In the thesis, we describe and apply the linearization test to many synchronization objects, and these tests can distinguish between the correct and faulty implementation of the object. We show how to optimize the linearization test by reducing the redundancy in the linearizer process and compare the optimized linearization test with the explicit linearization point test. With all the techniques, we apply the linearization test to a complicated object. 

The linearization test has some drawbacks. The complexity of the testing system usually grows exponentially regarding the number of processes and the size of the variable used. As a result, we usually use a small set of processes and variable values, which usually suffices to find a counterexample trace in a faulty system. Besides, sometimes reducing the variable size has no side effects. In the MenWomen object section, the variable \CSPM{stage} is declared as a Scala integer, but only value 0,1,2 is used.

Also, some of the synchronization objects tested in the thesis are more like artificially created objects for concurrent teaching. 

For future work, one can build CSP models for synchronization objects from other sources, such as JVM Source code. When more CSP modules become available, it will also be interesting to build a compiler from Java to CSP to enable large scale automatic testing of synchronization objects. Finally, one can look into improving linearization testing further to allow efficient testing of large systems. 

\newpage
\section{Reference}
\bibliographystyle{alpha}
\bibliography{project}

\newpage
\section{Appendix}
%TC:ignore
\input{source}
%TC:endignore
\end{document}